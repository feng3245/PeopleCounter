{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8-yl-s-WKMG"
   },
   "source": [
    "# Object Detection API Demo\n",
    "\n",
    "<table align=\"left\"><td>\n",
    "  <a target=\"_blank\"  href=\"https://colab.sandbox.google.com/github/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab\n",
    "  </a>\n",
    "</td><td>\n",
    "  <a target=\"_blank\"  href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb\">\n",
    "    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "</td></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cIrseUv6WKz"
   },
   "source": [
    "Welcome to the [Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection). This notebook will walk you step by step through the process of using a pre-trained model to detect objects in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VrJaG0cYN9yh"
   },
   "source": [
    "> **Important**: This tutorial is to help you through the first step towards using [Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection) to build models. If you just just need an off the shelf model that does the job, see the [TFHub object detection example](https://colab.sandbox.google.com/github/tensorflow/hub/blob/master/examples/colab/object_detection.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFSqkTCdWKMI"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtzUAo2x5yVO"
   },
   "outputs": [],
   "source": [
    "!wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n",
    "!tar xvzf ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n",
    "!wget http://images.cocodataset.org/zips/val2014.zip\n",
    "!unzip val2014.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bySekB97NwZp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-05-29 22:54:49--  http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.131.59\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.131.59|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 252872794 (241M) [application/zip]\n",
      "Saving to: ‘annotations_trainval2014.zip’\n",
      "\n",
      "annotations_trainva 100%[===================>] 241.16M  93.0MB/s    in 2.6s    \n",
      "\n",
      "2020-05-29 22:54:52 (93.0 MB/s) - ‘annotations_trainval2014.zip’ saved [252872794/252872794]\n",
      "\n",
      "Archive:  annotations_trainval2014.zip\n",
      "  inflating: annotations/instances_train2014.json  \n",
      "  inflating: annotations/instances_val2014.json  \n",
      "  inflating: annotations/person_keypoints_train2014.json  \n",
      "  inflating: annotations/person_keypoints_val2014.json  \n",
      "  inflating: annotations/captions_train2014.json  \n",
      "  inflating: annotations/captions_val2014.json  \n"
     ]
    }
   ],
   "source": [
    "!wget http://images.cocodataset.org/annotations/annotations_trainval2014.zip\n",
    "!unzip annotations_trainval2014.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0CstNAYpPHce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  val2014.zip\n",
      "   creating: usedVal2014/\n",
      "  inflating: usedVal2014/COCO_val2014_000000278175.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000486501.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000083915.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000373375.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000565543.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000482236.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000180366.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000330449.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000258680.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000337843.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000427471.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000432038.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000425964.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000513417.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000193041.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000404528.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000014635.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000546067.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000138022.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000463347.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000521863.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000047585.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000185305.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000564629.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000437947.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000488375.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000346841.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000559884.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000059463.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000180135.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000530631.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000194063.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000004936.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000562614.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000516372.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000353148.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000487217.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000459921.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000355276.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000001103.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000384616.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000490306.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000189868.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000476349.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000305423.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000069568.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000360851.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000142999.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000436252.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000176060.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000027969.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000422464.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000505845.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000512545.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000146568.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000516408.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000362368.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000183693.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000441518.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000479848.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000145048.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000105518.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000493862.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000549943.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000235621.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000140826.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000388926.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000129420.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000345993.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000033066.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000008690.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000228746.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000008718.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000281625.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000227808.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000078313.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000296182.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000338105.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000572907.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000051326.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000142826.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000284749.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000417285.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000237324.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000393203.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000195648.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000358268.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000048299.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000567432.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000560272.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000240798.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000360329.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000531126.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000040011.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000012236.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000258516.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000402077.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000258085.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000019579.jpg  \n",
      "  inflating: usedVal2014/COCO_val2014_000000523175.jpg  \n"
     ]
    }
   ],
   "source": [
    "!unzip val2014.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "awjrpqy-6MaQ"
   },
   "source": [
    "Important: If you're running on a local machine, be sure to follow the [installation instructions](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md). This notebook includes only what's necessary to run in Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling tensorflow-2.0.0b1:\n",
      "  Successfully uninstalled tensorflow-2.0.0b1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y tensorflow==1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.6/site-packages (2.0.0b1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.9.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: tb-nightly<1.14.0a20190604,>=1.14.0a20190603 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.14.0a20190603)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.19.0rc1)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.14.0.dev2019060501)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.29.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (0.30.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (3.12.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow) (47.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow) (2.6.9)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow) (2.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p3UGXxUii5Ym"
   },
   "source": [
    "### Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (47.1.1)\n"
     ]
    }
   ],
   "source": [
    "!/usr/bin/python3 -m pip install setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /usr/local/lib/python3.5/dist-packages (20.1.1)\n"
     ]
    }
   ],
   "source": [
    "!/usr/bin/python3 -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hGL97-GXjSUw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.*\n",
      "  Using cached tensorflow-2.2.0-cp35-cp35m-manylinux2010_x86_64.whl (516.2 MB)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Using cached absl-py-0.9.0.tar.gz (104 kB)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting numpy<2.0,>=1.16.0\n",
      "  Using cached numpy-1.19.0rc1.zip (7.3 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /usr/bin/python3 /usr/local/lib/python3.5/dist-packages/pip/_vendor/pep517/_in_process.py get_requires_for_build_wheel /tmp/tmpmi1c5l7c\n",
      "       cwd: /tmp/pip-install-68905acj/numpy\n",
      "  Complete output (19 lines):\n",
      "  Traceback (most recent call last):\n",
      "    File \"/usr/local/lib/python3.5/dist-packages/pip/_vendor/pep517/_in_process.py\", line 280, in <module>\n",
      "      main()\n",
      "    File \"/usr/local/lib/python3.5/dist-packages/pip/_vendor/pep517/_in_process.py\", line 263, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "    File \"/usr/local/lib/python3.5/dist-packages/pip/_vendor/pep517/_in_process.py\", line 114, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "    File \"/usr/local/lib/python3.5/dist-packages/setuptools/build_meta.py\", line 148, in get_requires_for_build_wheel\n",
      "      config_settings, requirements=['wheel'])\n",
      "    File \"/usr/local/lib/python3.5/dist-packages/setuptools/build_meta.py\", line 128, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"/usr/local/lib/python3.5/dist-packages/setuptools/build_meta.py\", line 250, in run_setup\n",
      "      self).run_setup(setup_script=setup_script)\n",
      "    File \"/usr/local/lib/python3.5/dist-packages/setuptools/build_meta.py\", line 143, in run_setup\n",
      "      exec(compile(code, __file__, 'exec'), locals())\n",
      "    File \"setup.py\", line 182\n",
      "      raise ValueError(f'Submodule {p} missing')\n",
      "                                              ^\n",
      "  SyntaxError: invalid syntax\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 /usr/local/lib/python3.5/dist-packages/pip/_vendor/pep517/_in_process.py get_requires_for_build_wheel /tmp/tmpmi1c5l7c Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!/usr/bin/python3 -m pip install -U --pre tensorflow==\"2.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-probability\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/c5/783644c55074f42070acfa1662145f4a0c59ff425495194aa2dc4052f22a/tensorflow_probability-0.10.0-py2.py3-none-any.whl (3.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.5MB 7.6MB/s eta 0:00:01    23% |███████▋                        | 839kB 22.4MB/s eta 0:00:01    68% |██████████████████████          | 2.4MB 34.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-probability) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from tensorflow-probability) (1.19.0rc1)\n",
      "Collecting cloudpickle>=1.2.2 (from tensorflow-probability)\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/a5/bb99276ec2685e11d34e4aefc0d9238626843ea51f974aa59c68317d34b2/cloudpickle-1.4.1-py3-none-any.whl\n",
      "Requirement already satisfied, skipping upgrade: decorator in /opt/conda/lib/python3.6/site-packages (from tensorflow-probability) (4.0.11)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.3.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow-probability) (0.3.3)\n",
      "\u001b[31mscikit-image 0.14.2 has requirement dask[array]>=1.0.0, but you'll have dask 0.16.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: cloudpickle, tensorflow-probability\n",
      "Successfully installed cloudpickle-1.4.1 tensorflow-probability-0.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --user --upgrade tensorflow-probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "baQ-ArwaniU_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Collecting tf_slim\n",
      "  Using cached tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python2.7/dist-packages (from tf_slim) (0.9.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
      "Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.1.10)\n",
      "Installing collected packages: tf-slim\n",
      "Successfully installed tf-slim-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!/usr/bin/python -m pip install tf_slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n_ap_s9ajTHH"
   },
   "source": [
    "Make sure you have `pycocotools` installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bg8ZyA47i3pY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycocotools\n",
      "  Using cached pycocotools-2.0.0.tar.gz (1.5 MB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /usr/bin/python3 -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-olu0gwzy/pycocotools/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-olu0gwzy/pycocotools/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-6633ucd4\n",
      "         cwd: /tmp/pip-install-olu0gwzy/pycocotools/\n",
      "    Complete output (5 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-olu0gwzy/pycocotools/setup.py\", line 2, in <module>\n",
      "        from Cython.Build import cythonize\n",
      "    ImportError: No module named 'Cython'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!/usr/bin/python3 -m pip  install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named tensorflow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f83c6d50081b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named tensorflow"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-vsOL3QR6kqs"
   },
   "source": [
    "Get `tensorflow/models` or `cd` to parent directory of the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ykA0c-om51s1"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pathlib",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cbf47c81328f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"models\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named pathlib"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "    while \"models\" in pathlib.Path.cwd().parts:\n",
    "        os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "    !git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O219m6yWAj9l"
   },
   "source": [
    "Compile protobufs and install the object_detection package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PY41vdYYNlXc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd models/research/\n",
    "protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s62yJyQUcYbp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/workspace/models/research\n",
      "Collecting Pillow>=1.0\n",
      "  Downloading Pillow-6.2.2-cp27-cp27mu-manylinux1_x86_64.whl (2.1 MB)\n",
      "Collecting Matplotlib>=2.1\n",
      "  Downloading matplotlib-2.2.5-cp27-cp27mu-manylinux1_x86_64.whl (12.8 MB)\n",
      "Collecting Cython>=0.28.1\n",
      "  Downloading Cython-0.29.19-cp27-cp27mu-manylinux1_x86_64.whl (1.9 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python2.7/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (2.8.1)\n",
      "Collecting backports.functools-lru-cache\n",
      "  Downloading backports.functools_lru_cache-1.6.1-py2.py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python2.7/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (1.16.6)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python2.7/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (1.15.0)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.1.0-cp27-cp27mu-manylinux1_x86_64.whl (93 kB)\n",
      "Collecting pytz\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting subprocess32\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python2.7/dist-packages (from kiwisolver>=1.0.1->Matplotlib>=2.1->object-detection==0.1) (20.7.0)\n",
      "Building wheels for collected packages: object-detection, subprocess32\n",
      "  Building wheel for object-detection (setup.py): started\n",
      "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
      "  Created wheel for object-detection: filename=object_detection-0.1-py2-none-any.whl size=1114558 sha256=4241b893fc4583010f93beb37fa8e348a932f22f707303a4a761df4a750eae6a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dCWD7F/wheels/9c/e9/83/719e05717722007b10fbb9b77aa6640ef56ef99bdb6d159628\n",
      "  Building wheel for subprocess32 (setup.py): started\n",
      "  Building wheel for subprocess32 (setup.py): finished with status 'done'\n",
      "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp27-cp27mu-linux_x86_64.whl size=45291 sha256=572c021a6ed9e32e9b08fb32428edef5871de7b50532a2f2669334291cdfe072\n",
      "  Stored in directory: /root/.cache/pip/wheels/e3/c7/6a/434fc8f2936acc4964ded8478435a8ef7c69eb41df7007a49f\n",
      "Successfully built object-detection subprocess32\n",
      "Installing collected packages: Pillow, backports.functools-lru-cache, pyparsing, cycler, kiwisolver, pytz, subprocess32, Matplotlib, Cython, object-detection\n",
      "Successfully installed Cython-0.29.19 Matplotlib-2.2.5 Pillow-6.2.2 backports.functools-lru-cache-1.6.1 cycler-0.10.0 kiwisolver-1.1.0 object-detection-0.1 pyparsing-2.4.7 pytz-2020.1 subprocess32-3.5.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd models/research\n",
    "/usr/bin/python -m pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LBdjK2G5ywuc"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hV4P5gyTWKMI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5FNuiRPWKMN"
   },
   "source": [
    "Import the object detection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4-IMl4b6BdGO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/object_detection/utils/visualization_utils.py:29: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 1073, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 456, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 486, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 438, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2724, in run_cell\n",
      "    self.events.trigger('post_run_cell')\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/events.py\", line 74, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/backend_inline.py\", line 164, in configure_once\n",
      "    activate_matplotlib(backend)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/pylabtools.py\", line 315, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py\", line 1425, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/backends/__init__.py\", line 17, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n"
     ]
    }
   ],
   "source": [
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RYPCiag2iz_q"
   },
   "source": [
    "Patches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mF-YlMl8c_bM"
   },
   "outputs": [],
   "source": [
    "# patch tf1 into `utils.ops`\n",
    "utils_ops.tf = tf.compat.v1\n",
    "\n",
    "# Patch the location of gfile\n",
    "tf.gfile = tf.io.gfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfn_tRFOWKMO"
   },
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_sEBLpVWKMQ"
   },
   "source": [
    "## Variables\n",
    "\n",
    "Any model exported using the `export_inference_graph.py` tool can be loaded here simply by changing the path.\n",
    "\n",
    "By default we use an \"SSD with Mobilenet\" model here. See the [detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) for a list of other models that can be run out-of-the-box with varying speeds and accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ai8pLZZWKMS"
   },
   "source": [
    "## Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zm8xp-0eoItE"
   },
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
    "    model_file = model_name + '.tar.gz'\n",
    "    model_dir = tf.keras.utils.get_file(fname=model_name, origin=base_url + model_file, untar=True)\n",
    "\n",
    "    model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "\n",
    "    model = tf.saved_model.load(str(model_dir))\n",
    "    model = model.signatures['serving_default']\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1MVVTcLWKMW"
   },
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hDbpHkiWWKMX"
   },
   "outputs": [],
   "source": [
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oVU3U_J6IJVb"
   },
   "source": [
    "For the sake of simplicity we will test on 2 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jG-zn5ykWKMd"
   },
   "outputs": [],
   "source": [
    "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
    "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('models/research/object_detection/test_images')\n",
    "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
    "TEST_IMAGE_PATHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0_1AGhrWKMc"
   },
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f7aOtOlebK7h"
   },
   "source": [
    "Load an object detection model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1XNT0wxybKR6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n",
      "187932672/187925923 [==============================] - 3s 0us/step\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "model_name = 'ssd_mobilenet_v2_coco_2018_03_29'\n",
    "detection_model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yN1AYfAEJIGp"
   },
   "source": [
    "Check the model's input signature, it expects a batch of 3-color images of type uint8: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CK4cnry6wsHY"
   },
   "outputs": [],
   "source": [
    "print(detection_model.inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q8u3BjpMJXZF"
   },
   "source": [
    "And returns several outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oLSZpfaYwuSk"
   },
   "outputs": [],
   "source": [
    "detection_model.output_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FZyKUJeuxvpT"
   },
   "outputs": [],
   "source": [
    "detection_model.output_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JP5qZ7sXJpwG"
   },
   "source": [
    "Add a wrapper function to call the model, and cleanup the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ajmR_exWyN76"
   },
   "outputs": [],
   "source": [
    "def run_inference_for_single_image(model, image):\n",
    "    image = np.asarray(image)\n",
    "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "    input_tensor = tf.convert_to_tensor(image)\n",
    "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "    input_tensor = input_tensor[tf.newaxis,...]\n",
    "\n",
    "    # Run inference\n",
    "    output_dict = model(input_tensor)\n",
    "\n",
    "    # All outputs are batches tensors.\n",
    "    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "    # We're only interested in the first num_detections.\n",
    "    num_detections = int(output_dict.pop('num_detections'))\n",
    "    output_dict = {key:value[0, :num_detections].numpy() for key,value in output_dict.items()}\n",
    "    output_dict['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
    "   \n",
    "    # Handle models with masks:\n",
    "    if 'detection_masks' in output_dict:\n",
    "        # Reframe the the bbox mask to the image size.\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(output_dict['detection_masks'], output_dict['detection_boxes'],image.shape[0], image.shape[1])      \n",
    "        detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5, tf.uint8)\n",
    "        output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
    "    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z1wq0LVyMRR_"
   },
   "source": [
    "Run it on each test image and show the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWh_1zz6aqxs"
   },
   "outputs": [],
   "source": [
    "def show_inference(model, image_path):\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    # result image with boxes and labels on it.\n",
    "    image_np = np.array(Image.open(image_path))\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(model, image_np)\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(image_np, output_dict['detection_boxes'], output_dict['detection_classes'], output_dict['detection_scores'], category_index, instance_masks=output_dict.get('detection_masks_reframed', None), use_normalized_coordinates=True, line_thickness=8)\n",
    "\n",
    "    display(Image.fromarray(image_np))\n",
    "def show_ground_truth(truth, image_path):\n",
    "    image_np = np.array(Image.open(image_path))\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(image_np, truth['detection_boxes'], truth['detection_classes'], np.array([1]*len(truth['detection_classes'])), category_index, instance_masks=truth.get('detection_masks_reframed', None), use_normalized_coordinates=False, line_thickness=8)\n",
    "    display(Image.fromarray(image_np))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PMVee5bjUHh3"
   },
   "outputs": [],
   "source": [
    "valImageIds = [26799,\n",
    " 319654,\n",
    " 317244,\n",
    " 536947,\n",
    " 31748,\n",
    " 73453,\n",
    " 448263,\n",
    " 408955,\n",
    " 408364,\n",
    " 137577,\n",
    " 293841,\n",
    " 420791,\n",
    " 110560,\n",
    " 234938,\n",
    " 68387,\n",
    " 163041,\n",
    " 34167,\n",
    " 148055,\n",
    " 129864,\n",
    " 554582,\n",
    " 319616,\n",
    " 350388,\n",
    " 152208,\n",
    " 44269,\n",
    " 444273,\n",
    " 434700,\n",
    " 457078,\n",
    " 73832,\n",
    " 208002,\n",
    " 15667,\n",
    " 558645,\n",
    " 413634,\n",
    " 189078,\n",
    " 418219,\n",
    " 460243,\n",
    " 407521,\n",
    " 205232,\n",
    " 552186,\n",
    " 128920,\n",
    " 180953,\n",
    " 75884,\n",
    " 488086,\n",
    " 567730,\n",
    " 308545,\n",
    " 548485,\n",
    " 495332,\n",
    " 191203,\n",
    " 327590,\n",
    " 511204,\n",
    " 170716,\n",
    " 144878,\n",
    " 386224,\n",
    " 459428,\n",
    " 280918,\n",
    " 256630,\n",
    " 207826,\n",
    " 524450,\n",
    " 369373,\n",
    " 112372,\n",
    " 86317,\n",
    " 331753,\n",
    " 264686,\n",
    " 35062,\n",
    " 315939,\n",
    " 12809,\n",
    " 410627,\n",
    " 135256,\n",
    " 15660,\n",
    " 73467,\n",
    " 159133,\n",
    " 398148,\n",
    " 460962,\n",
    " 58614,\n",
    " 126766,\n",
    " 148077,\n",
    " 33499,\n",
    " 497555,\n",
    " 503808,\n",
    " 146448,\n",
    " 435957,\n",
    " 318157,\n",
    " 83172,\n",
    " 287506,\n",
    " 410252,\n",
    " 110369,\n",
    " 216235,\n",
    " 492552,\n",
    " 440793,\n",
    " 94566,\n",
    " 385669,\n",
    " 302760,\n",
    " 197111,\n",
    " 370935,\n",
    " 37382,\n",
    " 195367,\n",
    " 104198,\n",
    " 101096,\n",
    " 162189,\n",
    " 45433,\n",
    " 408863]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.2.0.32-cp27-cp27mu-manylinux1_x86_64.whl (28.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 28.2 MB 117 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python2.7/dist-packages (from opencv-python) (1.16.6)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.2.0.32\n"
     ]
    }
   ],
   "source": [
    "!/usr/bin/python -m pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u5KB3fyYG99c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'info', u'images', u'licenses', u'annotations', u'categories']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1103: {'detection_boxes': array([[219.72, 178.96, 245.41, 222.92],\n",
       "         [219.52, 111.11, 244.84, 157.19],\n",
       "         [218.52, 260.85, 243.25, 304.82],\n",
       "         [250.17, 263.54, 267.35, 298.86],\n",
       "         [256.05, 309.3 , 267.93, 332.6 ],\n",
       "         [215.91, 350.09, 236.42, 390.09],\n",
       "         [219.47, 296.65, 239.48, 334.41],\n",
       "         [246.89, 182.22, 258.71, 208.88],\n",
       "         [217.9 , 214.64, 242.83, 242.89]]),\n",
       "  'detection_classes': array([16, 16, 16, 16, 16, 16, 16, 16, 16])},\n",
       " 4936: {'detection_boxes': array([[  0.  ,   0.95, 415.32, 640.  ],\n",
       "         [157.63, 365.87, 261.19, 433.71],\n",
       "         [ 28.72, 193.15, 111.07, 267.65],\n",
       "         [134.03, 289.95, 189.23, 358.35],\n",
       "         [131.5 , 420.05, 342.48, 639.54],\n",
       "         [174.15, 208.54, 237.33, 272.87],\n",
       "         [188.56, 328.  , 324.68, 413.18],\n",
       "         [302.34,   4.88, 413.77, 115.44],\n",
       "         [ 95.73, 347.94, 126.25, 396.34],\n",
       "         [187.71, 149.73, 257.44, 233.56],\n",
       "         [  2.1 , 220.79,  53.28, 311.54],\n",
       "         [ 63.95, 104.19, 128.26, 189.81]]),\n",
       "  'detection_classes': array([51, 56, 57, 57, 50, 56, 56, 56, 57, 56, 56, 56])},\n",
       " 8690: {'detection_boxes': array([[ 18.6 , 136.7 , 396.84, 351.52],\n",
       "         [ 73.35, 285.84, 396.94, 516.67],\n",
       "         [ 10.38,  74.25, 302.01, 175.94],\n",
       "         [390.29, 379.69, 474.43, 637.48],\n",
       "         [309.38,  52.5 , 480.  , 640.  ]]),\n",
       "  'detection_classes': array([ 1,  1,  1,  1, 20])},\n",
       " 8718: {'detection_boxes': array([[  0.  ,   0.96, 425.  , 640.  ],\n",
       "         [  1.44, 508.28, 209.15, 640.  ],\n",
       "         [148.03, 203.43, 392.53, 308.48],\n",
       "         [154.72, 263.6 , 413.54, 561.57],\n",
       "         [177.27, 258.82, 383.93, 548.7 ]]),\n",
       "  'detection_classes': array([67, 47, 50, 51, 61])},\n",
       " 12236: {'detection_boxes': array([[ 86.56, 144.26, 166.65, 304.18],\n",
       "         [204.64, 253.69, 304.51, 439.73],\n",
       "         [216.86,   0.  , 326.08, 192.54],\n",
       "         [203.19, 492.68, 218.4 , 501.32],\n",
       "         [269.39, 199.01, 360.  , 300.94],\n",
       "         [117.62, 308.02, 221.75, 364.24],\n",
       "         [ 52.56, 607.77, 117.71, 639.82],\n",
       "         [317.86,  51.57, 355.59, 100.57],\n",
       "         [311.51, 143.63, 360.  , 215.76],\n",
       "         [123.78,  36.4 , 223.28, 109.21],\n",
       "         [152.43, 342.16, 241.62, 411.89],\n",
       "         [122.1 , 374.39, 200.62, 431.77],\n",
       "         [ 43.4 , 413.76, 128.86, 511.68],\n",
       "         [ 32.78, 255.83,  86.56, 319.81],\n",
       "         [ 87.81,  81.75, 142.04, 117.31],\n",
       "         [142.06,  83.14, 248.61, 153.36],\n",
       "         [  1.47, 167.23,  62.16, 230.95],\n",
       "         [164.68, 390.97, 198.87, 412.13],\n",
       "         [225.14, 546.35, 273.33, 573.28],\n",
       "         [ 47.49, 270.08, 132.84, 319.66],\n",
       "         [  0.  ,   0.  , 359.  , 639.  ]]),\n",
       "  'detection_classes': array([28, 28, 28, 77,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 27,  1,  1,\n",
       "         31, 31,  1,  1])},\n",
       " 14635: {'detection_boxes': array([[2.9866e+02, 1.4009e+02, 3.6252e+02, 2.3485e+02],\n",
       "         [2.6231e+02, 1.0300e+00, 3.8308e+02, 4.5420e+01],\n",
       "         [2.6799e+02, 4.9479e+02, 3.6062e+02, 6.1670e+02],\n",
       "         [3.7695e+02, 2.3340e+02, 4.1637e+02, 2.6541e+02],\n",
       "         [3.7644e+02, 1.6260e+01, 4.0502e+02, 2.7990e+01],\n",
       "         [4.3646e+02, 3.2855e+02, 4.5785e+02, 4.1368e+02],\n",
       "         [3.6197e+02, 2.1081e+02, 3.8370e+02, 2.2525e+02],\n",
       "         [3.6488e+02, 1.1734e+02, 4.0155e+02, 1.2704e+02],\n",
       "         [3.8118e+02, 2.8424e+02, 4.0034e+02, 3.6510e+02],\n",
       "         [1.3249e+02, 2.6858e+02, 2.4575e+02, 3.0849e+02],\n",
       "         [2.1681e+02, 4.0018e+02, 4.8000e+02, 6.0728e+02],\n",
       "         [1.4670e+02, 1.2081e+02, 3.3115e+02, 1.9955e+02],\n",
       "         [2.3155e+02, 3.1286e+02, 2.4259e+02, 3.1668e+02],\n",
       "         [3.6060e+02, 2.1000e-01, 3.9318e+02, 1.0350e+01],\n",
       "         [2.5673e+02, 3.3391e+02, 2.6799e+02, 3.6494e+02],\n",
       "         [1.7130e+02, 2.3620e+02, 1.9940e+02, 2.7167e+02],\n",
       "         [2.4155e+02, 3.1078e+02, 2.5734e+02, 3.2281e+02],\n",
       "         [3.5906e+02, 0.0000e+00, 4.8000e+02, 4.3881e+02]]),\n",
       "  'detection_classes': array([62, 62, 62, 47, 48, 48, 48, 49, 49, 79,  1,  1, 50, 51, 51, 72, 51,\n",
       "         67])},\n",
       " 19579: {'detection_boxes': array([[ 60.48,   8.39, 223.24, 234.9 ],\n",
       "         [  0.  , 378.36, 223.24, 500.  ],\n",
       "         [  0.97, 320.45, 125.65, 406.17]]),\n",
       "  'detection_classes': array([54, 47, 47])},\n",
       " 27969: {'detection_boxes': array([[181.84, 542.82, 201.27, 575.66],\n",
       "         [ 55.17, 134.87, 381.71, 337.08],\n",
       "         [176.52,  55.37, 424.  , 536.48],\n",
       "         [170.01, 428.8 , 192.13, 483.58],\n",
       "         [127.94, 308.39, 192.5 , 429.69],\n",
       "         [100.83, 273.59, 197.62, 321.99]]),\n",
       "  'detection_classes': array([ 3,  1, 15,  8,  8,  1])},\n",
       " 33066: {'detection_boxes': array([[ 18.58,   1.43, 466.3 , 437.67],\n",
       "         [ 78.66, 104.99, 521.63, 326.47],\n",
       "         [ 92.5 , 213.64, 394.23, 415.52]]),\n",
       "  'detection_classes': array([62,  1, 88])},\n",
       " 40011: {'detection_boxes': array([[149.08, 232.76, 337.59, 562.65],\n",
       "         [268.59,  64.03, 349.24, 145.03],\n",
       "         [220.91, 105.67, 240.17, 123.52],\n",
       "         [267.98,  67.98, 353.81, 143.89],\n",
       "         [209.13, 344.64, 220.75, 363.06],\n",
       "         [207.  , 297.39, 217.08, 311.69],\n",
       "         [208.4 , 337.26, 219.98, 348.55],\n",
       "         [207.28, 325.46, 219.37, 334.94]]),\n",
       "  'detection_classes': array([ 7, 15, 15, 62, 62, 62, 62, 62])},\n",
       " 47585: {'detection_boxes': array([[  8.99,  19.96, 243.19, 367.35],\n",
       "         [179.13,  53.44, 603.31, 247.99],\n",
       "         [123.12, 179.37, 603.84, 361.61],\n",
       "         [190.14, 356.22, 424.01, 424.  ],\n",
       "         [202.3 , 399.3 , 231.23, 424.  ],\n",
       "         [188.85, 347.2 , 410.14, 382.14],\n",
       "         [204.83, 240.69, 335.79, 272.82]]),\n",
       "  'detection_classes': array([28,  1,  1,  1,  1,  1, 32])},\n",
       " 48299: {'detection_boxes': array([[153.54, 241.67, 211.44, 262.98],\n",
       "         [181.07,  86.4 , 215.32, 116.23],\n",
       "         [175.43, 115.22, 225.26, 142.46],\n",
       "         [160.24, 464.98, 182.03, 481.18],\n",
       "         [162.85, 182.61, 214.39, 210.1 ],\n",
       "         [149.06, 264.04, 206.59, 296.08],\n",
       "         [146.45, 297.79, 204.03, 321.88],\n",
       "         [152.27, 327.75, 202.36, 355.81],\n",
       "         [152.22, 383.33, 198.77, 409.64],\n",
       "         [152.4 , 434.49, 188.42, 460.07],\n",
       "         [130.83, 227.52, 186.05, 271.79],\n",
       "         [131.06, 324.89, 153.89, 341.38],\n",
       "         [133.91, 346.18, 158.45, 364.45],\n",
       "         [131.29, 379.63, 151.52, 395.34],\n",
       "         [152.67, 404.54, 198.19, 426.76],\n",
       "         [168.2 ,   0.  , 226.18,  33.63],\n",
       "         [129.54, 427.87, 156.52, 450.44],\n",
       "         [187.62,   1.52, 226.88,  27.85],\n",
       "         [140.84, 433.96, 156.38, 445.8 ],\n",
       "         [143.65, 384.72, 153.44, 394.33],\n",
       "         [157.75, 206.03, 213.88, 224.03],\n",
       "         [158.01, 462.49, 183.08, 482.92],\n",
       "         [154.74, 170.  , 169.69, 180.63],\n",
       "         [136.  , 124.  , 223.  , 521.  ]]),\n",
       "  'detection_classes': array([19, 21, 21, 21, 21, 21, 21, 21, 21, 21,  1,  1,  1,  1, 21,  1,  1,\n",
       "         19, 19, 19, 21, 21,  1, 21])},\n",
       " 51326: {'detection_boxes': array([[158.73, 346.4 , 422.2 , 639.06]]),\n",
       "  'detection_classes': array([86])},\n",
       " 59463: {'detection_boxes': array([[ 78.27,   6.45, 121.45,  49.79],\n",
       "         [312.62,   0.  , 394.4 ,  17.11],\n",
       "         [304.39, 407.52, 324.17, 415.94],\n",
       "         [284.39, 378.19, 310.72, 408.56],\n",
       "         [279.18, 386.88, 297.04, 426.  ],\n",
       "         [301.97, 393.23, 321.8 , 403.2 ],\n",
       "         [307.3 , 416.37, 332.2 , 425.27],\n",
       "         [304.51,  42.18, 313.22,  46.36],\n",
       "         [303.66,   7.52, 316.12,  12.  ],\n",
       "         [320.21, 394.66, 357.38, 425.63],\n",
       "         [304.04, 400.3 , 336.95, 409.23],\n",
       "         [302.9 ,  34.44, 311.78,  41.33],\n",
       "         [303.54,  13.67, 317.83,  18.37],\n",
       "         [305.55, 385.52, 334.7 , 400.58],\n",
       "         [341.91, 408.12, 378.14, 426.  ]]),\n",
       "  'detection_classes': array([85,  1,  1, 28, 28,  1,  1,  1,  1,  1,  1,  1,  1,  1, 62])},\n",
       " 69568: {'detection_boxes': array([[  5.75,  64.72, 632.81, 478.92],\n",
       "         [460.8 ,  51.2 , 576.75, 257.51],\n",
       "         [136.63,   5.75, 317.84, 198.47]]),\n",
       "  'detection_classes': array([ 1, 59, 78])},\n",
       " 78313: {'detection_boxes': array([[251.22, 418.3 , 275.15, 443.19],\n",
       "         [316.83, 233.35, 339.07, 273.99],\n",
       "         [ 97.8 , 264.36, 152.7 , 302.11],\n",
       "         [ 91.18,  58.94, 135.08, 110.23],\n",
       "         [281.12, 400.23, 309.88, 455.61],\n",
       "         [ 48.25, 335.68,  93.36, 366.75],\n",
       "         [149.31, 429.09, 167.93, 446.38],\n",
       "         [142.68, 381.98, 164.12, 406.6 ],\n",
       "         [152.3 , 445.56, 168.83, 454.28],\n",
       "         [159.53, 465.51, 170.68, 471.24],\n",
       "         [158.78, 459.62, 170.  , 466.39],\n",
       "         [ 30.13, 200.62,  62.48, 248.  ],\n",
       "         [276.58, 385.42, 293.7 , 426.47],\n",
       "         [274.  , 432.26, 296.44, 483.84],\n",
       "         [363.24, 226.08, 407.26, 284.15],\n",
       "         [307.18, 255.44, 329.01, 293.59],\n",
       "         [309.35, 212.25, 331.4 , 245.91],\n",
       "         [266.7 , 471.13, 288.37, 504.37],\n",
       "         [  0.  ,  63.57,  28.19, 126.49],\n",
       "         [ 44.75, 248.37,  74.62, 289.99],\n",
       "         [276.88, 383.26, 297.62, 395.01],\n",
       "         [247.85, 381.74, 419.36, 535.54],\n",
       "         [260.29, 463.29, 269.09, 475.93],\n",
       "         [231.99, 463.66, 280.4 , 517.52],\n",
       "         [ 88.02, 120.99, 142.3 , 173.39],\n",
       "         [252.62, 388.01, 278.47, 415.6 ],\n",
       "         [ 76.  , 397.32, 110.41, 423.81],\n",
       "         [266.31, 449.05, 281.37, 470.16],\n",
       "         [ 57.  , 141.  , 273.  , 388.  ]]),\n",
       "  'detection_classes': array([47, 51, 86, 86, 51, 86, 47, 47, 47, 47, 47, 51, 51, 51, 51, 51, 51,\n",
       "         51, 51, 51, 51, 67, 51, 62, 86, 86, 86, 47, 51])},\n",
       " 83915: {'detection_boxes': array([[132.63, 324.13, 145.63, 338.3 ]]),\n",
       "  'detection_classes': array([85])},\n",
       " 105518: {'detection_boxes': array([[0.0000e+00, 4.3986e+02, 9.8260e+01, 5.9413e+02],\n",
       "         [5.5000e-01, 1.4020e+02, 9.2180e+01, 3.4453e+02],\n",
       "         [2.6500e+00, 3.0459e+02, 9.2290e+01, 4.6748e+02],\n",
       "         [8.0000e-01, 9.6000e-01, 8.8120e+01, 1.4873e+02],\n",
       "         [6.0180e+01, 2.3622e+02, 3.4211e+02, 4.1840e+02],\n",
       "         [3.0193e+02, 2.1729e+02, 3.5958e+02, 3.5662e+02],\n",
       "         [5.7480e+01, 1.7558e+02, 7.4170e+01, 1.9344e+02],\n",
       "         [1.2750e+01, 1.3608e+02, 9.2030e+01, 2.4086e+02]]),\n",
       "  'detection_classes': array([ 2,  3,  3,  3,  1, 41,  2,  2])},\n",
       " 129420: {'detection_boxes': array([[151.9 , 255.16, 319.9 , 290.5 ],\n",
       "         [145.81,  77.54, 200.61,  99.28],\n",
       "         [125.78, 499.79, 326.53, 536.71],\n",
       "         [ 10.26, 472.1 , 420.95, 639.06],\n",
       "         [ 55.6 , 209.61, 426.84, 379.33],\n",
       "         [123.24,   0.  , 426.53, 105.81],\n",
       "         [ 62.83,  44.59, 426.62, 208.6 ]]),\n",
       "  'detection_classes': array([32, 32, 32,  1,  1,  1,  1])},\n",
       " 138022: {'detection_boxes': array([[325.53,  89.24, 362.13, 106.93],\n",
       "         [327.44,   3.43, 424.42,  25.99],\n",
       "         [243.7 , 127.97, 333.52, 405.61],\n",
       "         [250.58,  55.03, 570.62, 524.91],\n",
       "         [318.65, 531.59, 343.87, 560.92],\n",
       "         [307.98, 572.9 , 345.87, 599.38],\n",
       "         [322.69,  39.12, 354.97,  60.5 ]]),\n",
       "  'detection_classes': array([ 1,  1, 42,  8,  3, 64,  1])},\n",
       " 140826: {'detection_boxes': array([[ 33.84,   0.  , 534.03, 638.86],\n",
       "         [314.55, 340.17, 328.26, 351.09],\n",
       "         [318.94, 284.28, 327.06, 293.09]]),\n",
       "  'detection_classes': array([5, 1, 1])},\n",
       " 142826: {'detection_boxes': array([[277.48, 154.25, 460.85, 266.43],\n",
       "         [265.35, 379.69, 385.08, 518.83],\n",
       "         [122.97,  29.12, 337.62, 326.83],\n",
       "         [ 52.67, 313.89, 118.47, 489.71],\n",
       "         [ 45.96, 119.36, 128.03, 284.18],\n",
       "         [123.22, 327.77, 243.78, 617.3 ],\n",
       "         [315.04, 474.09, 404.13, 544.5 ],\n",
       "         [273.49, 463.61, 317.75, 511.51],\n",
       "         [324.56, 352.68, 410.82, 414.87],\n",
       "         [285.64, 344.88, 341.56, 396.59],\n",
       "         [295.55, 258.25, 343.94, 299.53],\n",
       "         [287.83, 126.32, 346.59, 172.03],\n",
       "         [345.19, 105.86, 439.78, 184.83],\n",
       "         [339.92, 240.27, 434.65, 308.04],\n",
       "         [182.99, 314.57, 246.27, 353.23]]),\n",
       "  'detection_classes': array([67, 67, 28, 28, 28, 28, 62, 62, 62, 62, 62, 62, 62, 62, 62])},\n",
       " 142999: {'detection_boxes': array([[130.04,  58.3 , 405.83, 358.  ],\n",
       "         [272.79,  13.57, 320.23,  82.04],\n",
       "         [209.21,  38.88, 224.36,  59.81]]),\n",
       "  'detection_classes': array([65, 84, 85])},\n",
       " 145048: {'detection_boxes': array([[ 45.57,  53.93, 475.06, 620.22]]),\n",
       "  'detection_classes': array([7])},\n",
       " 146568: {'detection_boxes': array([[3.4000e-01, 2.5993e+02, 7.8730e+01, 3.9333e+02],\n",
       "         [2.7223e+02, 5.5100e+00, 6.0442e+02, 2.0262e+02],\n",
       "         [3.1081e+02, 2.7500e+00, 5.2948e+02, 5.9140e+01],\n",
       "         [2.7412e+02, 1.9208e+02, 3.5070e+02, 3.4198e+02]]),\n",
       "  'detection_classes': array([72,  1, 62, 84])},\n",
       " 176060: {'detection_boxes': array([[  9.72,  20.54, 598.44, 602.42],\n",
       "         [254.01,  15.13, 601.95, 368.58],\n",
       "         [ 71.51, 286.06, 376.83, 602.37],\n",
       "         [  8.27,   6.89, 219.16, 372.16]]),\n",
       "  'detection_classes': array([67, 59, 59, 59])},\n",
       " 180135: {'detection_boxes': array([[  5.41,   0.  , 462.13, 252.58],\n",
       "         [349.44,   1.12, 488.76, 238.2 ]]),\n",
       "  'detection_classes': array([ 1, 41])},\n",
       " 180366: {'detection_boxes': array([[215.23, 103.  , 308.96, 263.69],\n",
       "         [ 74.2 , 233.02, 186.95, 640.  ],\n",
       "         [  1.08,  51.78, 472.45, 638.56]]),\n",
       "  'detection_classes': array([58, 28,  1])},\n",
       " 183693: {'detection_boxes': array([[194.78, 131.84, 255.48, 182.32],\n",
       "         [202.02, 198.32, 259.24, 212.31]]),\n",
       "  'detection_classes': array([85, 85])},\n",
       " 185305: {'detection_boxes': array([[ 76.84,  85.73, 272.55, 292.21]]),\n",
       "  'detection_classes': array([1])},\n",
       " 189868: {'detection_boxes': array([[281.21, 384.  , 380.12, 438.3 ],\n",
       "         [243.78,  48.65, 461.08, 205.41],\n",
       "         [ 84.3 , 147.48, 315.25, 434.14]]),\n",
       "  'detection_classes': array([18, 18, 19])},\n",
       " 193041: {'detection_boxes': array([[  1.28,   2.56, 480.  , 640.  ]]),\n",
       "  'detection_classes': array([60])},\n",
       " 194063: {'detection_boxes': array([[158.3 , 295.68, 167.54, 303.8 ],\n",
       "         [  5.76,  23.99, 105.55,  77.72],\n",
       "         [ 20.41, 608.82, 112.92, 640.  ],\n",
       "         [156.96, 289.98, 204.47, 316.65],\n",
       "         [ 24.45,  23.33,  86.45,  56.4 ],\n",
       "         [ 13.53, 632.04,  64.  , 640.  ],\n",
       "         [116.49, 234.85, 239.59, 310.15]]),\n",
       "  'detection_classes': array([37,  1,  1, 43, 62,  1,  1])},\n",
       " 195648: {'detection_boxes': array([[537.68, 292.08, 625.67, 429.37]]),\n",
       "  'detection_classes': array([15])},\n",
       " 227808: {'detection_boxes': array([[289.44,  58.1 , 389.11, 118.95],\n",
       "         [  5.91,  47.35, 640.  , 484.  ]]),\n",
       "  'detection_classes': array([77,  1])},\n",
       " 228746: {'detection_boxes': array([[112.52,  91.87, 473.81, 455.23]]),\n",
       "  'detection_classes': array([17])},\n",
       " 235621: {'detection_boxes': array([[158.43,  20.22, 432.58, 317.98],\n",
       "         [238.36, 135.35, 347.98, 300.89],\n",
       "         [213.15,  14.61, 350.58,  88.95]]),\n",
       "  'detection_classes': array([ 1, 42, 27])},\n",
       " 237324: {'detection_boxes': array([[264.03,  33.03, 630.14, 439.05],\n",
       "         [256.75, 214.27, 282.04, 352.61],\n",
       "         [232.39,  96.14, 311.32, 160.72],\n",
       "         [236.19, 152.84, 294.84, 188.36],\n",
       "         [234.34, 160.92, 271.65, 208.47],\n",
       "         [215.59,  42.13, 354.58,  88.75],\n",
       "         [248.23, 167.13, 293.19, 211.27],\n",
       "         [225.56, 426.04, 297.18, 440.  ],\n",
       "         [242.26, 255.88, 274.6 , 354.48],\n",
       "         [227.55, 339.75, 269.93, 353.59],\n",
       "         [309.73, 159.6 , 380.84, 238.62],\n",
       "         [249.67, 236.95, 282.31, 355.11],\n",
       "         [234.65, 215.87, 263.17, 244.38],\n",
       "         [233.75, 199.54, 271.18, 223.79],\n",
       "         [230.86, 316.23, 237.65, 333.47],\n",
       "         [233.2 , 411.43, 297.95, 430.22],\n",
       "         [262.65,  34.91, 631.69, 440.  ],\n",
       "         [161.01,   0.  , 361.84,  99.14]]),\n",
       "  'detection_classes': array([3, 3, 3, 3, 3, 1, 1, 1, 3, 1, 1, 3, 3, 3, 3, 1, 8, 6])},\n",
       " 240798: {'detection_boxes': array([[ 36.15, 294.23, 112.39, 562.68],\n",
       "         [ 17.53,   0.  , 292.76, 470.85],\n",
       "         [127.1 , 121.61, 387.55, 640.  ]]),\n",
       "  'detection_classes': array([50, 51, 52])},\n",
       " 258085: {'detection_boxes': array([[3.1380e+01, 1.3424e+02, 8.1560e+01, 1.4985e+02],\n",
       "         [9.5860e+01, 2.8977e+02, 1.5523e+02, 3.2731e+02],\n",
       "         [2.7790e+01, 5.7555e+02, 4.6850e+01, 5.8501e+02],\n",
       "         [2.3720e+01, 2.0023e+02, 6.7180e+01, 2.1109e+02],\n",
       "         [1.9980e+01, 2.4260e+02, 6.4160e+01, 2.5199e+02],\n",
       "         [3.7400e+00, 3.9886e+02, 1.5940e+01, 4.0302e+02],\n",
       "         [5.7670e+01, 5.7460e+02, 7.7020e+01, 5.9151e+02],\n",
       "         [2.5780e+01, 2.3546e+02, 2.6903e+02, 3.4638e+02],\n",
       "         [0.0000e+00, 1.7668e+02, 1.5824e+02, 2.3493e+02],\n",
       "         [3.5920e+01, 4.1647e+02, 2.0484e+02, 5.1937e+02],\n",
       "         [0.0000e+00, 2.2345e+02, 1.1144e+02, 2.6148e+02],\n",
       "         [2.6416e+02, 1.9751e+02, 4.2762e+02, 3.2011e+02],\n",
       "         [2.2066e+02, 6.7000e-01, 3.6146e+02, 1.1266e+02],\n",
       "         [2.2369e+02, 2.6288e+02, 3.8050e+02, 3.6647e+02],\n",
       "         [3.6381e+02, 1.5304e+02, 4.2677e+02, 2.4990e+02],\n",
       "         [2.4949e+02, 7.6690e+01, 4.2715e+02, 2.1843e+02],\n",
       "         [6.8180e+01, 7.0990e+01, 1.1939e+02, 1.1698e+02],\n",
       "         [4.2770e+01, 4.3980e+01, 7.1760e+01, 8.4960e+01],\n",
       "         [4.8990e+01, 0.0000e+00, 7.5700e+01, 1.6110e+01],\n",
       "         [6.8000e-01, 4.0269e+02, 1.3460e+02, 4.4785e+02],\n",
       "         [3.0000e-01, 1.0965e+02, 1.7233e+02, 1.7321e+02],\n",
       "         [7.5730e+01, 0.0000e+00, 1.3083e+02, 7.1230e+01],\n",
       "         [1.9252e+02, 3.3219e+02, 2.7852e+02, 3.8965e+02],\n",
       "         [1.5977e+02, 0.0000e+00, 2.3918e+02, 5.5850e+01],\n",
       "         [1.0106e+02, 4.3162e+02, 1.5141e+02, 4.5729e+02],\n",
       "         [1.5830e+01, 3.5631e+02, 4.1130e+01, 3.6354e+02],\n",
       "         [0.0000e+00, 1.0000e+00, 4.3100e+02, 6.3900e+02]]),\n",
       "  'detection_classes': array([32, 32, 32, 32, 32, 32, 84,  1,  1,  1,  1,  1,  1,  1,  1,  1, 62,\n",
       "         62, 62,  1,  1, 62,  1,  1, 32, 32,  1])},\n",
       " 258516: {'detection_boxes': array([[267.67, 251.88, 324.22, 365.46],\n",
       "         [  8.55, 469.2 , 234.17, 547.96],\n",
       "         [269.78, 248.6 , 323.48, 364.96]]),\n",
       "  'detection_classes': array([55, 44, 57])},\n",
       " 258680: {'detection_boxes': array([[455.88, 155.86, 640.  , 222.35],\n",
       "         [218.12,   0.  , 631.39, 427.  ],\n",
       "         [397.8 , 336.12, 459.26, 412.46],\n",
       "         [391.98,   7.95, 476.28,  47.23],\n",
       "         [427.91, 401.83, 518.62, 427.  ],\n",
       "         [ 26.72,   3.32, 313.56, 392.95]]),\n",
       "  'detection_classes': array([32,  1,  1,  1,  1, 28])},\n",
       " 278175: {'detection_boxes': array([[ 73.42, 137.79, 305.12, 376.45]]),\n",
       "  'detection_classes': array([23])},\n",
       " 281625: {'detection_boxes': array([[1.7402e+02, 2.3317e+02, 2.1769e+02, 2.6143e+02],\n",
       "         [1.8064e+02, 2.8135e+02, 2.2483e+02, 3.0737e+02],\n",
       "         [4.2804e+02, 3.4990e+02, 5.3260e+02, 4.0355e+02],\n",
       "         [4.3315e+02, 4.9000e-01, 4.7590e+02, 2.7660e+01],\n",
       "         [5.4133e+02, 1.8714e+02, 5.5650e+02, 2.0704e+02],\n",
       "         [5.3698e+02, 2.3441e+02, 5.5208e+02, 2.5328e+02],\n",
       "         [4.4366e+02, 5.5860e+01, 5.0370e+02, 8.4710e+01],\n",
       "         [4.4239e+02, 1.7492e+02, 4.9329e+02, 2.0102e+02],\n",
       "         [4.5206e+02, 9.2050e+01, 4.7845e+02, 1.1682e+02],\n",
       "         [4.4086e+02, 2.1270e+02, 4.9092e+02, 2.3085e+02],\n",
       "         [4.3863e+02, 2.8906e+02, 4.8393e+02, 3.1068e+02],\n",
       "         [4.4680e+02, 3.1363e+02, 4.7816e+02, 3.3349e+02],\n",
       "         [4.4078e+02, 1.3872e+02, 4.9531e+02, 1.6481e+02],\n",
       "         [4.4512e+02, 1.1004e+02, 4.8720e+02, 1.3589e+02],\n",
       "         [4.4356e+02, 1.7290e+01, 4.7466e+02, 3.8980e+01],\n",
       "         [4.4591e+02, 1.9632e+02, 4.8010e+02, 2.1789e+02],\n",
       "         [4.7398e+02, 8.2760e+01, 5.0274e+02, 1.1052e+02],\n",
       "         [5.9296e+02, 1.5244e+02, 6.4000e+02, 2.2687e+02],\n",
       "         [4.5615e+02, 3.3434e+02, 4.7644e+02, 3.6409e+02],\n",
       "         [4.6370e+02, 2.2945e+02, 4.8636e+02, 2.9824e+02],\n",
       "         [4.5974e+02, 3.7170e+01, 4.8000e+02, 7.0140e+01],\n",
       "         [4.6134e+02, 1.9055e+02, 4.6998e+02, 2.0398e+02],\n",
       "         [4.3300e+02, 3.8000e+01, 6.3000e+02, 2.5000e+02]]),\n",
       "  'detection_classes': array([85, 85,  1,  1, 16, 16,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 27,\n",
       "          1, 15, 15, 15, 31,  1])},\n",
       " 284749: {'detection_boxes': array([[474.73, 149.58, 582.04, 188.6 ],\n",
       "         [460.34, 306.82, 480.09, 317.15],\n",
       "         [481.38, 194.66, 577.78, 213.45],\n",
       "         [459.48, 151.97, 505.25, 171.34],\n",
       "         [484.57, 211.64, 616.88, 259.26],\n",
       "         [461.56, 219.81, 483.94, 224.22],\n",
       "         [456.93, 286.36, 482.4 , 303.77],\n",
       "         [483.24, 274.7 , 629.93, 317.84],\n",
       "         [456.65, 348.72, 601.42, 403.01],\n",
       "         [201.2 , 286.58, 260.14, 419.73],\n",
       "         [198.35, 143.52, 205.04, 153.11],\n",
       "         [202.37, 256.31, 229.77, 281.08],\n",
       "         [192.59, 200.78, 230.76, 223.18],\n",
       "         [452.64,  97.74, 513.35, 117.26],\n",
       "         [456.26, 116.8 , 509.83, 129.47],\n",
       "         [168.22,  89.83, 175.88, 126.78],\n",
       "         [ 91.42,  53.07,  99.03,  59.4 ],\n",
       "         [509.37,  31.85, 599.83, 230.59],\n",
       "         [415.83, 239.86, 430.96, 282.15],\n",
       "         [487.53, 399.78, 503.43, 426.65],\n",
       "         [438.98, 404.14, 448.48, 426.74],\n",
       "         [484.58, 321.72, 548.08, 352.75],\n",
       "         [424.12, 162.77, 437.81, 178.56],\n",
       "         [503.86, 381.15, 536.32, 421.25],\n",
       "         [345.  ,   0.  , 639.  , 426.  ]]),\n",
       "  'detection_classes': array([ 1,  1,  1,  1,  1,  1,  1,  1,  1, 38, 38, 38, 38,  1,  1, 38, 38,\n",
       "         38, 38, 38, 38,  1, 38,  2,  1])},\n",
       " 296182: {'detection_boxes': array([[299.1 , 448.51, 309.73, 488.12],\n",
       "         [188.14, 384.35, 197.38, 413.02],\n",
       "         [245.71, 172.18, 248.11, 193.38],\n",
       "         [185.35, 370.54, 203.32, 381.18],\n",
       "         [281.87, 426.29, 300.17, 440.7 ],\n",
       "         [225.45, 361.8 , 231.6 , 372.14],\n",
       "         [221.16, 360.15, 225.27, 369.75],\n",
       "         [241.27,  94.03, 248.15, 112.55],\n",
       "         [280.6 , 444.3 , 299.11, 467.27],\n",
       "         [238.79, 165.92, 246.76, 191.48],\n",
       "         [192.77,   2.73, 199.55,  28.87],\n",
       "         [225.55, 337.65, 232.08, 344.02],\n",
       "         [221.54, 350.26, 223.84, 353.94],\n",
       "         [196.94, 496.46, 202.26, 499.11],\n",
       "         [227.97, 328.79, 231.24, 334.07],\n",
       "         [187.3 , 226.92, 194.21, 235.04],\n",
       "         [287.3 , 435.68, 307.59, 454.02],\n",
       "         [221.78, 238.87, 225.88, 246.85],\n",
       "         [220.69, 392.02, 228.51, 398.62],\n",
       "         [223.2 , 450.18, 230.16, 464.53],\n",
       "         [219.57, 421.86, 225.03, 428.69]]),\n",
       "  'detection_classes': array([9, 9, 9, 9, 1, 1, 1, 1, 1, 1, 9, 1, 1, 9, 9, 9, 1, 1, 1, 1, 1])},\n",
       " 305423: {'detection_boxes': array([[465.05, 234.04, 549.26, 281.8 ],\n",
       "         [160.78,  12.32, 201.91,  32.41],\n",
       "         [181.8 , 318.85, 216.48, 345.9 ],\n",
       "         [290.03, 258.45, 563.7 , 399.89]]),\n",
       "  'detection_classes': array([41,  1,  2,  1])},\n",
       " 330449: {'detection_boxes': array([[0.0000e+00, 3.7657e+02, 1.4910e+02, 6.3837e+02],\n",
       "         [1.2000e+00, 3.7423e+02, 1.7060e+02, 6.3839e+02],\n",
       "         [2.4944e+02, 2.3562e+02, 2.6194e+02, 2.4641e+02],\n",
       "         [2.0952e+02, 4.3034e+02, 2.2384e+02, 4.9308e+02],\n",
       "         [2.3045e+02, 4.4449e+02, 2.5054e+02, 4.7016e+02],\n",
       "         [2.4094e+02, 1.9140e+02, 2.7728e+02, 2.9255e+02],\n",
       "         [0.0000e+00, 7.8600e+00, 1.0538e+02, 6.0190e+01],\n",
       "         [2.0000e-02, 1.1053e+02, 1.1429e+02, 2.3879e+02],\n",
       "         [1.1289e+02, 3.7020e+01, 1.2314e+02, 4.5960e+01],\n",
       "         [2.3579e+02, 4.6532e+02, 2.6796e+02, 4.9146e+02],\n",
       "         [9.0000e-02, 2.1466e+02, 1.4237e+02, 3.0376e+02]]),\n",
       "  'detection_classes': array([ 3,  8, 57, 57, 57, 57,  1,  3, 57, 57,  1])},\n",
       " 337843: {'detection_boxes': array([[  7.78, 189.46, 257.01, 431.95],\n",
       "         [211.22, 326.15, 278.15, 433.4 ]]),\n",
       "  'detection_classes': array([ 1, 41])},\n",
       " 338105: {'detection_boxes': array([[213.57, 117.57, 284.76, 209.26],\n",
       "         [212.38, 341.71, 242.28, 384.2 ],\n",
       "         [203.08, 383.81, 228.98, 412.49],\n",
       "         [208.94, 402.82, 241.54, 445.23],\n",
       "         [205.73, 421.05, 229.29, 457.41],\n",
       "         [207.06, 493.88, 238.35, 509.37],\n",
       "         [100.52, 433.15, 127.78, 441.51],\n",
       "         [ 95.97, 498.69, 122.76, 508.51],\n",
       "         [ 28.29, 145.01,  68.68, 159.96],\n",
       "         [101.15,  15.6 , 130.24,  27.5 ],\n",
       "         [192.9 , 461.11, 200.67, 468.44],\n",
       "         [192.52, 482.7 , 200.43, 486.08],\n",
       "         [213.71, 376.12, 238.26, 391.92],\n",
       "         [  0.  , 476.44, 397.04, 640.  ],\n",
       "         [ 19.55, 373.03,  62.71, 388.39],\n",
       "         [ 27.26, 255.28,  70.99, 276.71],\n",
       "         [208.08, 484.26, 233.45, 498.31],\n",
       "         [224.39,  26.74, 265.7 , 126.47]]),\n",
       "  'detection_classes': array([ 3,  3,  3,  3,  3,  3, 10, 10, 10, 10, 10, 10,  3,  8, 10, 10,  3,\n",
       "          3])},\n",
       " 345993: {'detection_boxes': array([[235.09, 386.7 , 261.96, 430.84],\n",
       "         [300.04, 239.77, 422.32, 280.85],\n",
       "         [ 73.73,  52.78, 422.04, 567.09],\n",
       "         [120.45,   0.96, 421.36, 185.32],\n",
       "         [ 60.26, 303.27, 424.08, 572.84]]),\n",
       "  'detection_classes': array([32, 32,  1,  1,  1])},\n",
       " 346841: {'detection_boxes': array([[176.23, 346.19, 304.39, 469.7 ]]),\n",
       "  'detection_classes': array([55])},\n",
       " 353148: {'detection_boxes': array([[ 69.98, 594.51,  84.38, 615.95],\n",
       "         [ 72.08,  80.89,  99.72, 111.28],\n",
       "         [ 73.18,  22.8 ,  96.61,  58.58],\n",
       "         [ 66.75, 361.87,  85.29, 397.89],\n",
       "         [ 68.39, 471.32,  80.6 , 507.07],\n",
       "         [ 68.46, 444.66,  90.82, 487.  ],\n",
       "         [ 73.11, 523.1 ,  99.96, 545.64],\n",
       "         [ 86.24, 360.31, 175.56, 449.35],\n",
       "         [ 96.3 , 157.14, 162.75, 238.06],\n",
       "         [ 79.28, 441.23, 155.36, 500.71],\n",
       "         [ 82.26,  78.7 , 129.73, 115.53],\n",
       "         [ 81.08, 123.52, 149.37, 174.6 ],\n",
       "         [ 90.64, 232.36, 182.79, 281.44],\n",
       "         [ 61.13,  51.93, 134.75,  84.02],\n",
       "         [ 63.63, 178.82, 110.86, 239.79],\n",
       "         [ 63.56, 267.66, 199.54, 317.2 ],\n",
       "         [ 68.02, 328.56, 113.07, 354.83],\n",
       "         [ 60.2 , 543.56, 118.71, 564.6 ],\n",
       "         [ 60.25, 430.07,  81.8 , 447.93],\n",
       "         [ 64.88, 416.86,  90.21, 431.85],\n",
       "         [ 67.71, 171.57, 106.17, 191.65],\n",
       "         [ 65.46, 394.87,  89.18, 411.63],\n",
       "         [ 76.31, 424.54, 132.04, 461.41],\n",
       "         [ 67.77,  34.76,  73.9 ,  41.03],\n",
       "         [ 83.31,  15.74,  96.81,  28.98],\n",
       "         [ 56.96,   0.  , 153.82,  28.03],\n",
       "         [ 83.88, 304.51, 182.86, 368.17],\n",
       "         [ 93.44, 478.37, 138.89, 526.6 ],\n",
       "         [ 89.98,  94.71, 141.4 , 142.07],\n",
       "         [ 83.76, 504.01, 131.01, 546.65],\n",
       "         [ 75.65, 367.98, 161.64, 404.79],\n",
       "         [ 75.94, 487.51, 106.5 , 543.89],\n",
       "         [ 72.12, 614.01,  80.27, 626.05],\n",
       "         [ 65.  ,  26.  , 137.  , 639.  ]]),\n",
       "  'detection_classes': array([ 3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  1,  1,  1,  1,\n",
       "          1,  1,  1,  1,  1,  1,  1, 37,  1,  4,  4,  4,  4,  1,  3,  3,  1])},\n",
       " 355276: {'detection_boxes': array([[217.06, 198.28, 381.75, 570.36]]),\n",
       "  'detection_classes': array([23])},\n",
       " 358268: {'detection_boxes': array([[202.31,   0.  , 284.73,  91.67],\n",
       "         [264.77, 450.82, 426.04, 640.  ],\n",
       "         [ 44.1 , 303.62, 420.98, 494.47],\n",
       "         [ 59.87, 128.18, 427.  , 330.16],\n",
       "         [234.18,  63.19, 412.26, 188.61],\n",
       "         [278.9 ,   0.  , 427.  , 143.6 ],\n",
       "         [152.34, 348.55, 336.43, 386.37],\n",
       "         [142.91, 133.39, 196.67, 158.75],\n",
       "         [382.25, 223.08, 402.72, 241.04],\n",
       "         [239.73, 129.72, 427.  , 207.43],\n",
       "         [215.72, 292.97, 241.02, 331.12]]),\n",
       "  'detection_classes': array([64, 63,  1,  1,  1,  1, 32, 75, 75, 63, 75])},\n",
       " 360329: {'detection_boxes': array([[ 48.31, 223.6 , 274.16, 365.17],\n",
       "         [ 47.67, 232.64, 225.7 , 310.78]]),\n",
       "  'detection_classes': array([52, 52])},\n",
       " 360851: {'detection_boxes': array([[131.27,  29.21, 388.58, 273.03],\n",
       "         [320.05,  86.42, 449.82, 220.69]]),\n",
       "  'detection_classes': array([ 1, 41])},\n",
       " 362368: {'detection_boxes': array([[  1.1 ,  60.44, 493.41, 309.89],\n",
       "         [ 39.41,   0.  , 495.5 ,  72.07],\n",
       "         [448.92,  13.51, 479.99, 135.69],\n",
       "         [ 94.7 ,  33.32, 121.62,  53.06],\n",
       "         [336.19,  60.87, 499.91, 256.45],\n",
       "         [382.91, 281.79, 500.  , 334.  ],\n",
       "         [407.75, 105.38, 436.09, 147.53]]),\n",
       "  'detection_classes': array([ 1,  1, 50, 50, 51,  1, 52])},\n",
       " 373375: {'detection_boxes': array([[ 11.54, 186.61, 473.2 , 504.81]]),\n",
       "  'detection_classes': array([25])},\n",
       " 384616: {'detection_boxes': array([[191.57, 371.3 , 466.01, 453.09]]),\n",
       "  'detection_classes': array([11])},\n",
       " 388926: {'detection_boxes': array([[203.54,  55.27, 407.47, 223.93],\n",
       "         [105.87, 264.53, 386.38, 486.09],\n",
       "         [102.15, 505.95, 385.49, 640.  ],\n",
       "         [232.06,  10.56, 325.95, 150.44],\n",
       "         [185.95,  36.07, 299.36,  88.6 ],\n",
       "         [170.88, 419.31, 386.69, 530.19],\n",
       "         [  0.  ,   0.  , 418.7 , 640.  ],\n",
       "         [178.84, 286.73, 217.98, 324.44]]),\n",
       "  'detection_classes': array([1, 1, 1, 1, 1, 1, 6, 1])},\n",
       " 393203: {'detection_boxes': array([[271.27, 270.88, 305.95, 303.68],\n",
       "         [290.51, 100.12, 324.73, 145.02],\n",
       "         [293.43, 113.8 , 334.22, 179.11],\n",
       "         [265.33,  54.22, 284.03,  65.84],\n",
       "         [268.04, 256.82, 274.81, 269.45],\n",
       "         [290.48, 100.17, 326.25, 143.92]]),\n",
       "  'detection_classes': array([20, 20, 20, 20, 20, 21])},\n",
       " 402077: {'detection_boxes': array([[100.93, 475.98, 187.91, 502.34],\n",
       "         [124.14, 612.37, 180.38, 630.41],\n",
       "         [331.71,  77.96, 389.81, 106.12],\n",
       "         [162.66, 268.07, 473.93, 502.3 ],\n",
       "         [ 33.44,  79.82, 474.61, 341.93],\n",
       "         [281.32, 393.96, 402.45, 449.43],\n",
       "         [180.92, 183.35, 216.43, 217.57],\n",
       "         [232.18, 456.12, 480.  , 640.  ],\n",
       "         [144.52, 501.73, 170.38, 551.5 ],\n",
       "         [134.07, 203.41, 171.28, 233.18]]),\n",
       "  'detection_classes': array([44, 44, 44,  1,  1, 57, 57, 63, 51, 57])},\n",
       " 404528: {'detection_boxes': array([[301.59, 162.27, 523.49, 257.  ],\n",
       "         [474.45, 117.86, 527.51, 180.47]]),\n",
       "  'detection_classes': array([ 1, 42])},\n",
       " 417285: {'detection_boxes': array([[ 41.17, 245.21, 217.35, 373.21],\n",
       "         [ 97.94, 426.85, 125.76, 526.16],\n",
       "         [165.48, 211.31, 256.64, 329.  ],\n",
       "         [ 89.73,   0.72, 230.27, 181.62],\n",
       "         [  7.93, 183.78, 141.98, 213.33],\n",
       "         [ 79.24, 498.74, 208.66, 634.74]]),\n",
       "  'detection_classes': array([47, 48, 50, 61,  1, 61])},\n",
       " 422464: {'detection_boxes': array([[162.3 , 351.93, 479.78, 618.83],\n",
       "         [268.87, 288.36, 324.11, 313.15]]),\n",
       "  'detection_classes': array([65, 62])},\n",
       " 425964: {'detection_boxes': array([[ 54.59, 149.19, 463.24, 556.76],\n",
       "         [268.58, 450.88, 418.52, 640.  ],\n",
       "         [383.27,  43.2 , 448.29, 149.31],\n",
       "         [395.5 ,  35.67, 480.  , 166.54],\n",
       "         [141.94,  45.35, 315.56, 152.19],\n",
       "         [102.5 , 282.55, 140.05, 320.8 ],\n",
       "         [372.8 , 337.13, 480.  , 506.67],\n",
       "         [393.71, 469.21, 472.45, 639.64],\n",
       "         [130.33,  47.62, 186.09,  68.77],\n",
       "         [270.4 , 127.94, 284.95, 152.8 ],\n",
       "         [188.47,  48.44, 220.42,  94.08],\n",
       "         [ 80.1 ,   2.49, 472.83, 234.39],\n",
       "         [272.36, 471.87, 314.59, 509.71],\n",
       "         [103.24, 310.66, 153.43, 405.81],\n",
       "         [223.02,   0.  , 362.25,  98.07]]),\n",
       "  'detection_classes': array([ 1,  1, 48, 49, 61, 67,  1,  1, 52, 52, 52, 67,  1,  1, 47])},\n",
       " 427471: {'detection_boxes': array([[ 62.42, 220.63, 402.51, 568.25]]),\n",
       "  'detection_classes': array([25])},\n",
       " 432038: {'detection_boxes': array([[136.95,  27.44, 200.54, 121.15],\n",
       "         [ 86.83, 147.87, 209.82, 319.91],\n",
       "         [ 91.07, 355.46, 216.9 , 472.76],\n",
       "         [ 99.46, 312.68, 204.64, 440.04],\n",
       "         [  0.59, 319.08,  51.93, 369.33],\n",
       "         [ 18.25, 309.06,  90.75, 363.22],\n",
       "         [  0.  , 255.21,  81.54, 312.06],\n",
       "         [ 29.84, 147.72,  96.99, 196.22],\n",
       "         [ 37.41, 104.85,  99.38, 151.68],\n",
       "         [ 28.26,  12.59,  94.76,  77.22],\n",
       "         [  0.  , 290.13,  61.69, 320.78],\n",
       "         [ 11.36, 389.94,  71.44, 438.92],\n",
       "         [ 18.63, 215.26,  89.61, 254.24],\n",
       "         [  0.  ,  37.05,  74.27, 125.83],\n",
       "         [ 36.16, 254.14,  90.72, 309.77],\n",
       "         [ 33.95,  79.27,  88.04, 117.51],\n",
       "         [  0.9 ,   0.6 ,  84.09,  37.53],\n",
       "         [ 55.02, 380.99,  92.57, 432.76],\n",
       "         [  0.  , 427.  , 287.  , 481.  ]]),\n",
       "  'detection_classes': array([18, 20, 20, 20,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         18,  1])},\n",
       " 436252: {'detection_boxes': array([[222.56,  69.89, 543.25, 365.91],\n",
       "         [126.97, 178.92, 402.24, 278.02]]),\n",
       "  'detection_classes': array([19,  1])},\n",
       " 437947: {'detection_boxes': array([[286.88, 512.11, 321.06, 536.1 ],\n",
       "         [336.22, 595.55, 362.  , 640.  ],\n",
       "         [221.77, 363.94, 378.53, 428.91],\n",
       "         [228.92,  43.41, 427.52, 226.81],\n",
       "         [124.86, 236.54, 148.05, 256.33],\n",
       "         [277.01, 471.56, 315.16, 494.53]]),\n",
       "  'detection_classes': array([44, 81, 79, 82, 16, 44])},\n",
       " 441518: {'detection_boxes': array([[ 85.2 , 315.15, 421.42, 640.  ],\n",
       "         [ 49.35, 180.62, 141.48, 262.72],\n",
       "         [  0.  ,   0.92, 248.27, 263.85],\n",
       "         [  7.08, 104.33, 393.48, 611.47],\n",
       "         [271.92,   4.2 , 410.1 , 170.59],\n",
       "         [146.53, 306.49, 256.27, 460.02],\n",
       "         [182.92, 362.84, 196.24, 411.26]]),\n",
       "  'detection_classes': array([63, 63, 63,  1, 73, 73, 75])},\n",
       " 459921: {'detection_boxes': array([[263.86, 200.41, 298.17, 215.59],\n",
       "         [263.77, 184.37, 297.84, 200.44],\n",
       "         [340.08, 244.76, 348.77, 355.28],\n",
       "         [222.26, 381.27, 639.56, 480.  ],\n",
       "         [320.12, 339.44, 339.34, 357.71]]),\n",
       "  'detection_classes': array([44, 44, 81,  1, 47])},\n",
       " 463347: {'detection_boxes': array([[246.07,  59.91, 407.93, 356.98],\n",
       "         [244.5 , 237.73, 253.83, 241.8 ],\n",
       "         [245.12, 233.41, 252.71, 236.61],\n",
       "         [243.59, 162.56, 252.96, 177.62],\n",
       "         [236.26,  94.46, 258.12, 125.33],\n",
       "         [239.41, 139.25, 252.97, 156.45],\n",
       "         [244.96, 177.64, 252.65, 186.47]]),\n",
       "  'detection_classes': array([28,  1,  1,  3,  3,  3,  3])},\n",
       " 476349: {'detection_boxes': array([[139.14, 194.39, 274.3 , 315.25],\n",
       "         [219.86, 141.8 , 273.95, 364.77]]),\n",
       "  'detection_classes': array([ 1, 36])},\n",
       " 479848: {'detection_boxes': array([[3.6473e+02, 2.4499e+02, 5.3540e+02, 3.2895e+02],\n",
       "         [2.8431e+02, 2.2416e+02, 4.0328e+02, 2.7673e+02],\n",
       "         [3.8951e+02, 4.1300e+00, 5.1888e+02, 7.7080e+01],\n",
       "         [3.4072e+02, 9.1900e+00, 4.5967e+02, 9.7270e+01],\n",
       "         [2.0520e+01, 9.1510e+01, 1.5062e+02, 1.3322e+02],\n",
       "         [3.4331e+02, 3.4612e+02, 5.4053e+02, 4.2270e+02],\n",
       "         [4.4962e+02, 1.0291e+02, 5.3175e+02, 1.9677e+02],\n",
       "         [3.7810e+01, 7.8690e+01, 8.0770e+01, 8.7860e+01],\n",
       "         [1.8510e+01, 8.2690e+01, 1.3387e+02, 1.0988e+02],\n",
       "         [3.1010e+01, 5.6920e+01, 1.0652e+02, 8.9460e+01],\n",
       "         [2.8000e-01, 3.6295e+02, 6.2670e+01, 3.9437e+02],\n",
       "         [1.5770e+01, 1.4976e+02, 3.2270e+01, 1.5530e+02],\n",
       "         [5.6700e+00, 1.5977e+02, 2.6040e+01, 1.6551e+02],\n",
       "         [1.2900e+00, 1.6644e+02, 1.9770e+01, 1.7639e+02],\n",
       "         [1.7980e+01, 1.3020e+02, 2.6520e+01, 1.3447e+02],\n",
       "         [2.1085e+02, 2.9792e+02, 3.5890e+02, 3.4322e+02],\n",
       "         [0.0000e+00, 3.8818e+02, 8.1380e+01, 4.1222e+02],\n",
       "         [2.6000e-01, 4.0502e+02, 6.5440e+01, 4.2331e+02],\n",
       "         [3.3950e+01, 1.4970e+01, 6.6700e+01, 4.0650e+01],\n",
       "         [2.9350e+01, 0.0000e+00, 2.4883e+02, 9.9640e+01],\n",
       "         [1.5811e+02, 0.0000e+00, 2.0588e+02, 3.3270e+01],\n",
       "         [1.6280e+01, 1.3715e+02, 2.5830e+01, 1.4089e+02],\n",
       "         [1.1200e+00, 1.8901e+02, 3.5465e+02, 3.9887e+02]]),\n",
       "  'detection_classes': array([44, 44, 44, 44,  1, 47, 58,  1,  1,  1,  1, 44, 44, 44, 44, 44,  1,\n",
       "          1,  1,  1,  1, 44,  1])},\n",
       " 482236: {'detection_boxes': array([[453.49, 275.47, 528.15, 302.72],\n",
       "         [453.89, 259.6 , 512.43, 283.87],\n",
       "         [488.7 ,  24.77, 513.69,  30.93],\n",
       "         [490.52,  17.1 , 510.61,  23.61],\n",
       "         [491.26,  72.13, 504.7 , 100.75],\n",
       "         [487.99,  81.57, 511.81,  91.17],\n",
       "         [501.87,  63.74, 515.63,  79.82],\n",
       "         [501.79,  50.11, 515.64,  61.12],\n",
       "         [497.32, 164.92, 556.86, 316.95],\n",
       "         [498.88, 442.48, 519.05, 466.15],\n",
       "         [479.41, 357.6 , 484.82, 362.45],\n",
       "         [498.9 , 170.99, 530.45, 186.12],\n",
       "         [179.93, 203.18, 212.13, 238.9 ],\n",
       "         [508.06, 467.71, 517.82, 474.22]]),\n",
       "  'detection_classes': array([ 1,  1,  1,  1, 42,  1,  1,  1, 62, 62,  1,  1, 38,  1])},\n",
       " 486501: {'detection_boxes': array([[ 92.9 , 139.35, 474.84, 628.65],\n",
       "         [ 19.91, 470.86,  92.34, 494.14],\n",
       "         [ 87.37, 429.3 , 179.06, 494.02],\n",
       "         [ 96.  ,  88.45, 473.53, 637.48],\n",
       "         [ 24.09, 442.22,  94.96, 479.07]]),\n",
       "  'detection_classes': array([17, 90, 47, 81, 87])},\n",
       " 487217: {'detection_boxes': array([[1.6521e+02, 1.5044e+02, 1.9163e+02, 1.6984e+02],\n",
       "         [2.2493e+02, 2.5887e+02, 2.4486e+02, 2.7029e+02],\n",
       "         [2.0787e+02, 3.9935e+02, 2.4140e+02, 4.0632e+02],\n",
       "         [2.6763e+02, 3.3113e+02, 2.9804e+02, 3.3989e+02],\n",
       "         [2.6329e+02, 3.5015e+02, 2.8596e+02, 3.6222e+02],\n",
       "         [2.6705e+02, 3.0824e+02, 2.9928e+02, 3.2430e+02],\n",
       "         [2.6230e+02, 2.8912e+02, 2.9731e+02, 3.0399e+02],\n",
       "         [2.6812e+02, 2.6808e+02, 2.9662e+02, 2.7583e+02],\n",
       "         [2.2033e+02, 4.1263e+02, 2.4326e+02, 4.2150e+02],\n",
       "         [2.8007e+02, 3.4281e+02, 2.9769e+02, 3.5360e+02],\n",
       "         [2.6963e+02, 4.1879e+02, 3.2440e+02, 5.8309e+02],\n",
       "         [2.6622e+02, 1.8641e+02, 2.9989e+02, 2.5812e+02],\n",
       "         [2.6691e+02, 1.2022e+02, 2.9480e+02, 1.5822e+02],\n",
       "         [2.6650e+02, 3.6843e+02, 2.9551e+02, 3.8118e+02],\n",
       "         [2.6500e+02, 3.7000e-01, 2.9872e+02, 4.4080e+01],\n",
       "         [2.6112e+02, 5.1529e+02, 2.8744e+02, 5.7307e+02],\n",
       "         [2.6364e+02, 6.0409e+02, 2.9005e+02, 6.4000e+02],\n",
       "         [2.6724e+02, 7.0390e+01, 2.9879e+02, 1.2844e+02],\n",
       "         [2.7205e+02, 4.1409e+02, 2.9658e+02, 4.7326e+02],\n",
       "         [2.6608e+02, 1.8574e+02, 3.0032e+02, 2.5935e+02],\n",
       "         [2.6939e+02, 2.7589e+02, 2.9610e+02, 2.8639e+02]]),\n",
       "  'detection_classes': array([10, 10, 10,  1,  1,  1,  1,  1, 10,  1,  3,  3,  3,  1,  3,  3,  3,\n",
       "          3,  3,  8,  1])},\n",
       " 488375: {'detection_boxes': array([[183.99, 247.52, 266.9 , 324.29],\n",
       "         [148.64, 269.56, 163.5 , 293.02],\n",
       "         [ 57.75,  47.65, 417.95, 297.31],\n",
       "         [  6.87, 445.08, 414.66, 640.  ],\n",
       "         [  9.75, 533.35,  80.52, 591.7 ],\n",
       "         [126.83, 397.24, 337.42, 467.12],\n",
       "         [358.08, 268.8 , 414.69, 402.3 ],\n",
       "         [159.42, 301.56, 165.4 , 307.72],\n",
       "         [167.64, 196.53, 203.93, 231.2 ],\n",
       "         [226.6 ,  22.65, 299.83,  53.54],\n",
       "         [176.  , 413.68, 302.45, 440.  ],\n",
       "         [173.48,  37.28, 190.01,  60.72]]),\n",
       "  'detection_classes': array([62, 62,  1,  1,  1,  1, 35, 47, 62, 62, 62, 62])},\n",
       " 490306: {'detection_boxes': array([[336.09, 174.92, 440.66, 196.96],\n",
       "         [ 52.62, 153.54, 584.99, 318.57],\n",
       "         [155.83, 457.77, 181.72, 468.12],\n",
       "         [195.89, 427.5 , 202.34, 430.63]]),\n",
       "  'detection_classes': array([34,  1, 10, 10])},\n",
       " 493862: {'detection_boxes': array([[208.63, 153.06, 231.63, 192.31],\n",
       "         [  5.81,  38.74, 381.6 , 226.64],\n",
       "         [124.35, 218.47, 173.53, 305.69]]),\n",
       "  'detection_classes': array([18,  1, 43])},\n",
       " 505845: {'detection_boxes': array([[232.24,   5.65, 284.71,  38.81],\n",
       "         [ 39.91,  51.34, 428.22, 560.9 ]]),\n",
       "  'detection_classes': array([4, 6])},\n",
       " 512545: {'detection_boxes': array([[193.41,  66.28, 269.89, 154.66],\n",
       "         [179.03, 174.4 , 274.63, 317.24],\n",
       "         [193.32, 433.47, 290.4 , 588.46],\n",
       "         [208.78, 582.87, 274.06, 640.  ],\n",
       "         [177.14, 269.11, 270.81, 395.15],\n",
       "         [183.91, 414.82, 273.41, 513.94],\n",
       "         [181.  , 342.73, 223.33, 423.53],\n",
       "         [168.32, 282.13, 191.08, 338.11],\n",
       "         [202.  , 140.6 , 253.62, 183.32],\n",
       "         [160.06, 224.93, 173.81, 264.14],\n",
       "         [166.37, 204.31, 172.29, 221.04],\n",
       "         [171.44, 604.29, 209.1 , 640.  ],\n",
       "         [168.47, 367.28, 186.93, 464.02],\n",
       "         [182.43, 541.05, 232.26, 628.26],\n",
       "         [147.  ,   1.  , 263.  , 639.  ]]),\n",
       "  'detection_classes': array([20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20])},\n",
       " 513417: {'detection_boxes': array([[ 78.51, 208.71, 354.24, 524.65]]),\n",
       "  'detection_classes': array([22])},\n",
       " 516372: {'detection_boxes': array([[ 66.11, 336.64,  92.19, 418.55],\n",
       "         [269.81, 266.79, 446.6 , 363.21],\n",
       "         [227.55, 389.43, 421.13, 638.49],\n",
       "         [ 61.63, 311.7 , 175.41, 635.26],\n",
       "         [ 69.3 , 346.21,  94.15, 418.48]]),\n",
       "  'detection_classes': array([ 3, 11,  3,  8,  3])},\n",
       " 516408: {'detection_boxes': array([[  2.53,  91.01, 215.73, 479.49],\n",
       "         [165.49, 161.68, 362.97, 210.27],\n",
       "         [146.8 ,  27.11, 206.05,  37.34],\n",
       "         [146.95,  36.26, 207.29,  46.28],\n",
       "         [ 74.  ,  69.97, 206.15,  94.5 ],\n",
       "         [149.98,  81.28, 205.36,  94.44],\n",
       "         [ 76.63,  51.16, 205.59,  67.32],\n",
       "         [ 76.15,  61.  , 209.79,  76.97],\n",
       "         [148.14,  44.11, 207.49,  54.46]]),\n",
       "  'detection_classes': array([72, 17, 84, 84, 84, 84, 84, 84, 84])},\n",
       " 521863: {'detection_boxes': array([[202.14, 216.65, 231.62, 233.35],\n",
       "         [205.31, 179.52, 229.84, 192.11],\n",
       "         [175.98, 117.16, 275.49, 183.82],\n",
       "         [168.64, 185.82, 185.46, 197.74],\n",
       "         [161.02, 127.76, 181.51, 135.48],\n",
       "         [175.52, 255.79, 241.83, 280.4 ],\n",
       "         [173.78, 126.76, 186.06, 134.94],\n",
       "         [173.11, 234.31, 218.45, 253.74],\n",
       "         [182.44, 214.28, 225.6 , 230.47],\n",
       "         [190.86, 178.62, 216.52, 196.85],\n",
       "         [262.35, 124.22, 281.42, 168.73],\n",
       "         [172.01, 252.71, 231.09, 268.55],\n",
       "         [171.27, 280.44, 233.33, 296.17],\n",
       "         [156.7 , 167.75, 178.75, 178.82],\n",
       "         [169.98, 202.05, 212.31, 216.07],\n",
       "         [159.81, 160.82, 180.48, 168.31],\n",
       "         [174.74, 186.89, 220.81, 203.65],\n",
       "         [140.  ,  81.  , 182.  , 217.  ]]),\n",
       "  'detection_classes': array([ 2,  2,  1,  1,  1,  1,  2,  1,  1,  1, 41,  1,  1,  1,  1,  1,  1,\n",
       "          1])},\n",
       " 523175: {'detection_boxes': array([[ 72.17,  72.48, 309.13, 473.65],\n",
       "         [210.  , 130.59, 263.82, 198.53],\n",
       "         [269.01, 275.53, 328.87, 346.83],\n",
       "         [  0.  ,   1.95, 370.13, 495.78],\n",
       "         [186.79, 341.65, 236.97, 372.46],\n",
       "         [  1.01,   0.  , 251.76, 500.  ]]),\n",
       "  'detection_classes': array([50, 57, 57, 51, 57, 67])},\n",
       " 530631: {'detection_boxes': array([[191.96, 225.77, 230.24, 339.91],\n",
       "         [ 93.03, 529.55, 281.22, 640.  ],\n",
       "         [131.3 ,  17.22, 398.21, 513.36],\n",
       "         [ 62.47,  16.35, 217.31, 201.22],\n",
       "         [107.62, 174.05, 229.72, 255.45],\n",
       "         [178.96, 455.58, 480.  , 639.11]]),\n",
       "  'detection_classes': array([1, 4, 4, 4, 4, 1])},\n",
       " 531126: {'detection_boxes': array([[113.  , 357.76, 418.83, 490.47],\n",
       "         [146.61, 566.76, 212.66, 605.97],\n",
       "         [194.29, 306.1 , 372.18, 350.3 ],\n",
       "         [157.19, 275.3 , 345.09, 314.01],\n",
       "         [117.07,  50.86, 196.71, 111.31],\n",
       "         [158.28, 241.81, 377.1 , 300.34],\n",
       "         [163.95, 604.39, 184.02, 635.29],\n",
       "         [104.59,   0.96, 422.2 ,  62.37],\n",
       "         [146.7 , 515.8 , 222.38, 571.53],\n",
       "         [149.27,  44.39, 427.  , 129.28],\n",
       "         [146.6 ,  99.94, 427.  , 166.44],\n",
       "         [369.38, 340.21, 407.08, 378.39],\n",
       "         [144.82, 196.98, 399.1 , 258.29],\n",
       "         [134.  ,  26.  , 426.  , 639.  ]]),\n",
       "  'detection_classes': array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 37,  1,  1])},\n",
       " 546067: {'detection_boxes': array([[ 47.03, 301.99, 207.84, 393.22],\n",
       "         [ 57.79, 344.71, 138.45, 395.86],\n",
       "         [ 83.14, 393.17, 177.25, 444.82],\n",
       "         [224.46,  54.09, 318.69,  99.75],\n",
       "         [166.72, 223.33, 404.46, 530.01]]),\n",
       "  'detection_classes': array([ 1,  1,  1,  1, 22])},\n",
       " 549943: {'detection_boxes': array([[194.75,   9.84, 214.82,  35.1 ],\n",
       "         [187.7 , 176.99, 210.82, 232.72],\n",
       "         [189.33,  74.49, 211.74, 139.69],\n",
       "         [190.68, 555.95, 233.54, 607.49],\n",
       "         [186.92, 462.53, 211.8 , 488.35],\n",
       "         [194.28, 373.74, 201.84, 383.75],\n",
       "         [195.09, 535.66, 226.7 , 570.65],\n",
       "         [186.13, 509.88, 220.32, 554.  ],\n",
       "         [183.43,  15.29, 209.48,  30.  ],\n",
       "         [ 88.92,  45.17, 128.3 ,  80.52],\n",
       "         [186.03, 275.59, 206.38, 316.9 ],\n",
       "         [180.46, 107.57, 188.23, 113.14],\n",
       "         [193.96, 346.74, 203.77, 356.39],\n",
       "         [194.68, 237.23, 204.05, 260.06],\n",
       "         [190.66, 351.88, 202.14, 364.1 ],\n",
       "         [186.59, 178.51, 212.62, 233.59],\n",
       "         [172.52, 595.6 , 238.93, 640.  ],\n",
       "         [176.49, 416.97, 181.89, 419.91],\n",
       "         [185.75, 411.64, 202.28, 428.55],\n",
       "         [188.48, 321.66, 205.59, 347.52],\n",
       "         [175.15, 403.24, 184.23, 409.82],\n",
       "         [194.3 , 484.86, 213.7 , 497.5 ],\n",
       "         [187.56, 493.  , 217.03, 519.67],\n",
       "         [162.72, 453.36, 174.4 , 456.27],\n",
       "         [178.  , 319.  , 217.  , 521.  ]]),\n",
       "  'detection_classes': array([ 2,  3,  3,  3,  3,  3,  3,  3,  1, 13,  8,  1,  3,  3,  3,  8,  8,\n",
       "         10,  8,  8, 10,  3,  8, 10,  3])},\n",
       " 559884: {'detection_boxes': array([[ 20.1 , 219.22, 217.31, 409.73],\n",
       "         [ 95.95, 314.7 , 425.04, 548.81],\n",
       "         [ 12.17,  22.13, 419.36, 371.78]]),\n",
       "  'detection_classes': array([13,  1,  8])},\n",
       " 560272: {'detection_boxes': array([[2.2188e+02, 1.5034e+02, 4.1450e+02, 6.3987e+02],\n",
       "         [2.4000e-01, 2.8300e+00, 2.5790e+02, 4.7946e+02]]),\n",
       "  'detection_classes': array([5, 5])},\n",
       " 562614: {'detection_boxes': array([[294.96, 114.09, 319.89, 139.03],\n",
       "         [190.62, 412.04, 352.53, 527.76],\n",
       "         [170.2 , 237.21, 331.18, 327.29],\n",
       "         [193.7 , 139.09, 277.98, 173.99],\n",
       "         [194.26, 396.32, 320.41, 448.11]]),\n",
       "  'detection_classes': array([37,  1,  1,  1,  1])},\n",
       " 564629: {'detection_boxes': array([[184.45,  53.93, 268.58, 124.04],\n",
       "         [355.96,  53.93, 455.19, 174.74],\n",
       "         [409.26, 171.28, 477.36, 364.46]]),\n",
       "  'detection_classes': array([78, 79, 81])},\n",
       " 565543: {'detection_boxes': array([[170.75,  78.06, 281.45, 171.86],\n",
       "         [113.46, 370.71, 159.29, 542.81],\n",
       "         [191.33, 296.95, 213.23, 367.37],\n",
       "         [195.09, 210.63, 271.51, 277.98],\n",
       "         [219.94,  51.82, 260.19,  83.19],\n",
       "         [199.17,   0.56, 260.25,  35.81]]),\n",
       "  'detection_classes': array([28, 28, 28, 28, 28, 28])},\n",
       " 567432: {'detection_boxes': array([[236.3 , 170.55, 411.61, 377.31]]),\n",
       "  'detection_classes': array([5])},\n",
       " 572907: {'detection_boxes': array([[1.4826e+02, 3.5236e+02, 1.6048e+02, 3.6477e+02],\n",
       "         [2.1150e+02, 4.7520e+01, 2.6191e+02, 1.0366e+02],\n",
       "         [9.1970e+01, 2.5755e+02, 3.4823e+02, 3.6361e+02],\n",
       "         [8.1410e+01, 1.3668e+02, 1.4542e+02, 1.9952e+02],\n",
       "         [8.9150e+01, 6.9940e+01, 1.4607e+02, 1.3744e+02],\n",
       "         [1.5740e+01, 5.4800e+01, 1.0166e+02, 1.1627e+02],\n",
       "         [2.0460e+01, 1.4753e+02, 1.4113e+02, 2.2227e+02],\n",
       "         [2.7000e-01, 2.0422e+02, 6.5180e+01, 2.9696e+02],\n",
       "         [6.3090e+01, 3.2406e+02, 1.1698e+02, 3.6966e+02],\n",
       "         [8.8430e+01, 3.8733e+02, 1.4596e+02, 4.4147e+02],\n",
       "         [8.5700e+01, 5.1360e+01, 1.2603e+02, 7.5280e+01],\n",
       "         [1.8420e+01, 4.0081e+02, 8.7920e+01, 4.7192e+02],\n",
       "         [1.2084e+02, 9.2960e+01, 1.4565e+02, 1.0116e+02],\n",
       "         [1.1582e+02, 4.0888e+02, 1.4535e+02, 4.2536e+02],\n",
       "         [6.2790e+01, 2.1132e+02, 1.3111e+02, 2.6351e+02],\n",
       "         [1.1056e+02, 2.8311e+02, 1.4798e+02, 3.2917e+02],\n",
       "         [7.2120e+01, 2.6399e+02, 9.7490e+01, 2.8840e+02],\n",
       "         [6.4960e+01, 2.5489e+02, 1.1735e+02, 2.9170e+02],\n",
       "         [8.8810e+01, 1.5380e+01, 1.4612e+02, 7.1010e+01],\n",
       "         [6.4920e+01, 3.6685e+02, 1.1094e+02, 4.0835e+02],\n",
       "         [4.2850e+01, 1.3903e+02, 6.4700e+01, 1.5615e+02],\n",
       "         [6.4370e+01, 1.4060e+01, 8.8300e+01, 5.5950e+01],\n",
       "         [4.1560e+01, 3.5150e+02, 7.9930e+01, 3.9040e+02],\n",
       "         [4.0830e+01, 2.8329e+02, 6.4880e+01, 3.2444e+02],\n",
       "         [1.1290e+02, 2.3147e+02, 1.4578e+02, 2.7712e+02],\n",
       "         [4.1350e+01, 1.9824e+02, 1.0906e+02, 2.4076e+02],\n",
       "         [9.7310e+01, 3.3733e+02, 1.4520e+02, 3.8587e+02],\n",
       "         [4.0560e+01, 9.9040e+01, 6.9900e+01, 1.3886e+02],\n",
       "         [0.0000e+00, 1.2000e+01, 2.5900e+02, 4.7500e+02]]),\n",
       "  'detection_classes': array([37, 62,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 32, 32, 62, 62, 43,\n",
       "         62,  1, 62, 62, 62, 62, 62, 62, 62,  1, 62,  1])}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "with open('annotations/instances_val2014.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    print([k for k in data])\n",
    "valImageIds = {int(li.split('.')[0].split('_')[-1]): cv2.imread('val2014/'+li).shape for li in listdir('val2014') if int(li.split('.')[0].split('_')[-1]) in [da['image_id'] for da in data['annotations']]}\n",
    "imgbboxes = {}\n",
    "ground_truth = {}\n",
    " #if da['image_id'] in valImageIds\n",
    "setvalImageIds = set(valImageIds)\n",
    "for da in data['annotations']:\n",
    "    if da['image_id'] in setvalImageIds:\n",
    "        if not da['image_id'] in imgbboxes:\n",
    "            imgbboxes[da['image_id']] = [da['bbox']]\n",
    "        else:\n",
    "            imgbboxes[da['image_id']].append(da['bbox'])\n",
    "for da in data['annotations']:\n",
    "    if da['image_id'] in setvalImageIds:\n",
    "        if not da['image_id'] in ground_truth:\n",
    "            ground_truth[da['image_id']] = { 'detection_boxes' : np.array([[da['bbox'][1],da['bbox'][0], da['bbox'][1] + da['bbox'][3], da['bbox'][0] + da['bbox'][2]]]), 'detection_classes' : np.array([da['category_id']])}\n",
    "        else:\n",
    "            ground_truth[da['image_id']]['detection_boxes'] = np.append(ground_truth[da['image_id']]['detection_boxes'], np.array([[da['bbox'][1], da['bbox'][0], da['bbox'][1] +  da['bbox'][3], da['bbox'][0] + da['bbox'][2]]]), axis = 0)\n",
    "            ground_truth[da['image_id']]['detection_classes'] = np.append(ground_truth[da['image_id']]['detection_classes'], da['category_id'])\n",
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4vfK9NZOT0Nc"
   },
   "outputs": [],
   "source": [
    "[k for k in valImageIds][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1xpBOcBdHKC"
   },
   "outputs": [],
   "source": [
    "data['annotations'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3a5wMHN8WKMh"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "for image_path in ['val2014/'+li for li in listdir('val2014')[:5]]:\n",
    "    show_inference(detection_model, image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gGzSdtHzOPH_"
   },
   "outputs": [],
   "source": [
    "def intersects(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    return interArea > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I32COwa8Jx1U"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def bb_intersection_over_union(boxA, boxB):\n",
    "\t# determine the (x, y)-coordinates of the intersection rectangle\n",
    "\txA = max(boxA[0], boxB[0])\n",
    "\tyA = max(boxA[1], boxB[1])\n",
    "\txB = min(boxA[2], boxB[2])\n",
    "\tyB = min(boxA[3], boxB[3])\n",
    "\t# compute the area of intersection rectangle\n",
    "\tinterArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\t# compute the area of both the prediction and ground-truth\n",
    "\t# rectangles\n",
    "\tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "\tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\t# compute the intersection over union by taking the intersection\n",
    "\t# area and dividing it by the sum of prediction + ground-truth\n",
    "\t# areas - the interesection area\n",
    "\tiou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\t# return the intersection over union value\n",
    "\treturn iou\n",
    "def calculate_IOU(model, image_path, bboxes):\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    # result image with boxes and labels on it.\n",
    "    image_np = np.array(Image.open(image_path))\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(model, image_np)\n",
    "    gt_bboxs = bboxes[int(image_path.split('/')[-1].split('.')[0].split('_')[-1])]\n",
    "    detectedboxes = output_dict['detection_boxes']\n",
    "    detectedboxes = [[dbx[0]*image_np.shape[0],dbx[1]*image_np.shape[1], dbx[2]*image_np.shape[0],dbx[3]*image_np.shape[1]] for dbx in detectedboxes]\n",
    "    if len(detectedboxes) == 0 and len(gt_bboxs) == 0:\n",
    "        return 1\n",
    "    if len(detectedboxes) == 0:\n",
    "        return 0\n",
    "    return sum([sum([bb_intersection_over_union(gtb, dbb) for gtb in gt_bboxs if intersects(gtb, dbb)])/len([gtb for gtb in gt_bboxs if intersects(gtb, dbb)]) if len([gtb for gtb in gt_bboxs if intersects(gtb, dbb)]) > 0 else 0 for dbb in detectedboxes])/len(detectedboxes)\n",
    "def calculate_optimized_IOU(infer_network, net_input_shape, image_path, bboxes):\n",
    "    infer_optimized(infer_network, net_input_shape, image_path)\n",
    "    gt_bboxs = bboxes[int(image_path.split('/')[-1].split('.')[0].split('_')[-1])]\n",
    "    if infer_network.wait() == 0:\n",
    "        output = infer_network.extract_output()\n",
    "        detectedboxes = [[int(o[3]*width), int(o[4]*height), int(o[5]*width), int(o[6]*height)] for o in output[0][0]]\n",
    "    if len(detectedboxes) == 0 and len(gt_bboxs) == 0:\n",
    "        return 1\n",
    "    if len(detectedboxes) == 0:\n",
    "        return 0\n",
    "    return sum([sum([bb_intersection_over_union(gtb, dbb) for gtb in gt_bboxs if intersects(gtb, dbb)])/len([gtb for gtb in gt_bboxs if intersects(gtb, dbb)]) if len([gtb for gtb in gt_bboxs if intersects(gtb, dbb)]) > 0 else 0 for dbb in detectedboxes])/len(detectedboxes)\n",
    "def check_pred(model, image_path, bboxes):\n",
    "    image_np = np.array(Image.open(image_path))\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(model, image_np)\n",
    "    gt_bboxs = bboxes[int(image_path.split('/')[-1].split('.')[0])]\n",
    "    detectedboxes = output_dict['detection_boxes']\n",
    "    detectedboxes = [[dbx[0]*image_np.shape[0],dbx[1]*image_np.shape[1], dbx[2]*image_np.shape[0],dbx[3]*image_np.shape[1]] for dbx in detectedboxes]\n",
    "    return detectedboxes, gt_bboxs\n",
    "def inference_time(model, image_path):\n",
    "    image_np = np.array(Image.open(image_path))\n",
    "    startTime = time.time()\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(model, image_np)\n",
    "    return time.time() - startTime\n",
    "def infer_optimized(infer_network, net_input_shape, image_path):\n",
    "    frame = np.array(Image.open(image_path))\n",
    "    width = image_np.shape[1]\n",
    "    height = image_np.shape[0]\n",
    "    p_frame = cv2.resize(frame, (net_input_shape[3], net_input_shape[2]))\n",
    "    p_frame = p_frame.transpose((2,0,1))\n",
    "    p_frame = p_frame.reshape(1, *p_frame.shape)\n",
    "    startTime = time.time()\n",
    "    infer_network.async_inference(p_frame)\n",
    "def inference_optimized_time(infer_network, net_input_shape, image_path):\n",
    "    infer_optimized(infer_network, net_input_shape, image_path)\n",
    "    if infer_network.wait() == 0:\n",
    "        return time.time() - startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I7Scfq4UWh0u"
   },
   "outputs": [],
   "source": [
    "check_pred(detection_model, ['val2014/'+li for li in listdir('val2014') if int(li.split('.')[0].split('_')[-1]) in [da['image_id'] for da in data['annotations']]][1], imgbboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hKu226JTRQHO"
   },
   "outputs": [],
   "source": [
    "imgbboxes = { g:ground_truth[g]['detection_boxes'] for g in ground_truth}\n",
    "ious = [calculate_IOU(detection_model, image_path, imgbboxes) for image_path in ['val2014/'+li for li in listdir('val2014') if int(li.split('.')[0].split('_')[-1]) in ground_truth][:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MA_CMKWqqHtu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4086891604267041\n"
     ]
    }
   ],
   "source": [
    "avgiou = sum(ious)/len(ious)\n",
    "print(avgiou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pztkK21MraWQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2551904726028442\n"
     ]
    }
   ],
   "source": [
    "infTimes = [inference_time(detection_model, image_path) for image_path in ['val2014/'+li for li in listdir('val2014') if int(li.split('.')[0].split('_')[-1]) in ground_truth][:100]]\n",
    "print(sum(infTimes)/len(infTimes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-openvino-contrib-python\n",
      "\u001b[31m  Could not find a version that satisfies the requirement opencv-openvino-contrib-python (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for opencv-openvino-contrib-python\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-openvino-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "for p in '/opt/intel/openvino_2019.3.376/python/python3.5/:/opt/intel/openvino_2019.3.376/opencv/lib:/opt/intel/opencl:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/openvx/lib:/opt/intel/openvino_2019.3.376/opencv/lib:/opt/intel/opencl:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/openvx/lib:'.split(':'):\n",
    "    sys.path.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/opt/spark-2.4.3-bin-hadoop2.7/python',\n",
       " '/opt/spark-2.4.3-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip',\n",
       " '/home/workspace',\n",
       " '/opt/conda/lib/python36.zip',\n",
       " '/opt/conda/lib/python3.6',\n",
       " '/opt/conda/lib/python3.6/lib-dynload',\n",
       " '/root/.local/lib/python3.6/site-packages',\n",
       " '/opt/conda/lib/python3.6/site-packages',\n",
       " '/opt/conda/lib/python3.6/site-packages/Mako-1.0.7-py3.6.egg',\n",
       " '/opt/conda/lib/python3.6/site-packages/cycler-0.10.0-py3.6.egg',\n",
       " '/opt/conda/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg',\n",
       " '/opt/conda/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/root/.ipython',\n",
       " '/opt/intel/openvino_2019.3.376/opencv/lib',\n",
       " '/opt/intel/opencl',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64',\n",
       " '/opt/intel/openvino_2019.3.376/openvx/lib',\n",
       " '/opt/intel/openvino_2019.3.376/opencv/lib',\n",
       " '/opt/intel/opencl',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64',\n",
       " '/opt/intel/openvino_2019.3.376/openvx/lib',\n",
       " '',\n",
       " '/opt/intel',\n",
       " '/opt/intel/openvino_2019.3.376/opencv/lib',\n",
       " '/opt/intel/opencl',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64',\n",
       " '/opt/intel/openvino_2019.3.376/openvx/lib',\n",
       " '/opt/intel/openvino_2019.3.376/opencv/lib',\n",
       " '/opt/intel/opencl',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64',\n",
       " '/opt/intel/openvino_2019.3.376/openvx/lib',\n",
       " '',\n",
       " '/opt/intel/openvino_2019.3.376/python/python3.5/',\n",
       " '/opt/intel/openvino_2019.3.376/opencv/lib',\n",
       " '/opt/intel/opencl',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64',\n",
       " '/opt/intel/openvino_2019.3.376/openvx/lib',\n",
       " '/opt/intel/openvino_2019.3.376/opencv/lib',\n",
       " '/opt/intel/opencl',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib',\n",
       " '/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64',\n",
       " '/opt/intel/openvino_2019.3.376/openvx/lib',\n",
       " '']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LD_LIBRARY_PATH=/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/opencv/lib:/opt/intel/opencl:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/openvx/lib:/opt/intel/openvino_2019.3.376/opencv/lib:/opt/intel/opencl:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/openvx/lib:\n",
      "env: JUPYTER_PATH=/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/opencv/lib:/opt/intel/opencl:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/openvx/lib:/opt/intel/openvino_2019.3.376/opencv/lib:/opt/intel/opencl:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/openvx/lib:\n"
     ]
    }
   ],
   "source": [
    "%set_env LD_LIBRARY_PATH=/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/opencv/lib:/opt/intel/opencl:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/openvx/lib:/opt/intel/openvino_2019.3.376/opencv/lib:/opt/intel/opencl:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/openvx/lib:\n",
    "%set_env JUPYTER_PATH=/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/opencv/lib:/opt/intel/opencl:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/openvx/lib:/opt/intel/openvino_2019.3.376/opencv/lib:/opt/intel/opencl:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/openvx/lib:                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/intel/openvino_2019.3.376/opencv/lib:/opt/intel/opencl:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/openvx/lib:/opt/intel/openvino_2019.3.376/opencv/lib:/opt/intel/opencl:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/openvx/lib:'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import subprocess\n",
    "# Call a bash script\n",
    "subprocess.call(['/opt/intel/openvino/bin/setupvars.sh', '-pyver', '3.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python_version = 3.6\n",
      "[setupvars.sh] OpenVINO environment initialized\n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/bin/setupvars.sh -pyver 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'LD_LIBRARY_PATH'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9c9967a87dfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LD_LIBRARY_PATH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PATH'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LD_LIBRARY_PATH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/UserDict.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__missing__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'LD_LIBRARY_PATH'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['LD_LIBRARY_PATH']\n",
    "os.environ['PATH'] += ':'+os.environ['LD_LIBRARY_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/opencv/lib:/opt/intel/opencl:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/openvx/lib:/opt/intel/openvino_2019.3.376/opencv/lib:/opt/intel/opencl:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/hddl/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/gna/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/mkltiny_lnx/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/external/tbb/lib:/opt/intel/openvino_2019.3.376/deployment_tools/inference_engine/lib/intel64:/opt/intel/openvino_2019.3.376/openvx/lib:'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-80c59c67decd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minfer_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Network' is not defined"
     ]
    }
   ],
   "source": [
    "infer_network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nLlmm9JojEKm"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libinference_engine.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-54e7af5cf1a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0minference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimgbboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'detection_boxes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minfer_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minfer_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'frozen_inference_graph.xml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CPU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_sse4.so'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnet_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/workspace/inference.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopenvino\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_engine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIENetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIECore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/intel/openvino_2019.3.376/python/python3.5/openvino/inference_engine/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mie_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'IENetwork'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IEPlugin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IECore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"get_version\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libinference_engine.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "from inference import Network\n",
    "imgbboxes = { g:ground_truth[g]['detection_boxes'] for g in ground_truth}\n",
    "infer_network = Network()\n",
    "infer_network.load_model('frozen_inference_graph.xml', 'CPU', '/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/libcpu_extension_sse4.so')\n",
    "net_input_shape = infer_network.get_input_shape()\n",
    "ious = [calculate_optimized_IOU(infer_network, net_input_shape, image_path, imgbboxes) for image_path in ['val2014/'+li for li in listdir('val2014') if int(li.split('.')[0].split('_')[-1]) in ground_truth][:100]]\n",
    "avgiou = sum(ious)/len(ious)\n",
    "print(avgiou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infTimes = [inference_optimized_time(infer_network, net_input_shape, image_path) for image_path in ['val2014/'+li for li in listdir('val2014') if int(li.split('.')[0].split('_')[-1]) in ground_truth][:100]]\n",
    "print(sum(infTimes)/len(infTimes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ie_api.so  __init__.py\n"
     ]
    }
   ],
   "source": [
    "!ls /opt/intel/openvino_2019.3.376/python/python3.6/openvino/inference_engine/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of object_detection_tutorial.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "envOpenv36",
   "language": "python",
   "name": "envopenv36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
